# æ¨™æº–åº«å°å…¥
import os
import logging
import tempfile
import time
import base64
import glob
from pathlib import Path

# ç¬¬ä¸‰æ–¹åº«å°å…¥
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
import google.generativeai as genai
from pydub import AudioSegment

# æœ¬åœ°æ¨¡çµ„å°å…¥
from whisper_stt import get_model_description
from transcript_refiner import refine_transcript
from markitdown_utils import (
    convert_file_to_markdown, convert_url_to_markdown,
    extract_keywords, save_uploaded_file
)

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å®šç¾©å¯ç”¨çš„ OpenAI æ¨¡å‹
AVAILABLE_MODELS = {
    "gpt-4o": "gpt-4o",
    "gpt-4o-mini": "gpt-4o-mini",
    "o3-mini": "o3-mini",
    "o1-mini": "o1-mini"
}

# æ¨¡å‹è¨­å®šå’Œåƒ¹æ ¼ï¼ˆUSD per 1M tokensï¼‰
MODEL_CONFIG = {
    "gpt-4o": {
        "display_name": "gpt-4o",
        "input": 2.50,          # $2.50 per 1M tokens
        "cached_input": 1.25,   # $1.25 per 1M tokens
        "output": 10.00         # $10.00 per 1M tokens
    },
    "gpt-4o-mini": {
        "display_name": "gpt-4o-mini",
        "input": 0.15,          # $0.15 per 1M tokens
        "cached_input": 0.075,  # $0.075 per 1M tokens
        "output": 0.60          # $0.60 per 1M tokens
    },
    "o1-mini": {
        "display_name": "o1-mini",
        "input": 1.10,          # $1.10 per 1M tokens
        "cached_input": 0.55,   # $0.55 per 1M tokens
        "output": 4.40          # $4.40 per 1M tokens
    },
    "o3-mini": {
        "display_name": "o3-mini",
        "input": 1.10,          # $1.10 per 1M tokens
        "cached_input": 0.55,   # $0.55 per 1M tokens
        "output": 4.40          # $4.40 per 1M tokens
    },
    "gemini-2.5-pro-exp-03-25": {
        "display_name": "Gemini 2.5 Pro Experimental",
        "input": 0.00,          # åƒ¹æ ¼å¾…å®š
        "cached_input": 0.00,   # åƒ¹æ ¼å¾…å®š
        "output": 0.00          # åƒ¹æ ¼å¾…å®š
    }
}

# åŒ¯ç‡è¨­å®š
USD_TO_NTD = 31.5

# è½‰éŒ„æœå‹™èªªæ˜
TRANSCRIPTION_SERVICE_INFO = {
    "Whisper": """
    ### Whisper æ¨¡å‹
    - é–‹æºçš„èªéŸ³è½‰æ–‡å­—æ¨¡å‹
    - æ”¯æ´å¤šç¨®èªè¨€
    - å¯é›¢ç·šä½¿ç”¨
    """,
    "ElevenLabs": """
    ### ElevenLabs æ¨¡å‹
    - å•†æ¥­ç´šèªéŸ³è½‰æ–‡å­—æœå‹™
    - æ”¯æ´ 99 ç¨®èªè¨€
    - æä¾›èªªè©±è€…è¾¨è­˜åŠŸèƒ½
    """,
    "OpenAI 2025 New": """
    ### OpenAI 2025 å…¨æ–°æ¨¡å‹
    - gpt-4o-transcribeï¼šé«˜ç²¾åº¦ã€å¤šèªè¨€æ”¯æ´
    - gpt-4o-mini-transcribeï¼šè¼•é‡å¿«é€Ÿã€æ€§åƒ¹æ¯”é«˜
    - è‡ªå‹•èªè¨€æª¢æ¸¬
    - æ›´å¥½çš„ä¸­æ–‡è½‰éŒ„æ•ˆæœ
    """
}

# å„ªåŒ–æœå‹™èªªæ˜
OPTIMIZATION_SERVICE_INFO = {
    "OpenAI": """
    ### OpenAI å„ªåŒ–æ¨¡å‹
    - å°ˆæ¥­çš„æ–‡å­—å„ªåŒ–å’Œæ ¡æ­£
    - æ”¯æ´å¤šç¨®èªè¨€
    - å¯è‡ªè¨‚å„ªåŒ–ç¨‹åº¦
    """,
    "Gemini": """
    ### Google Gemini 2.5 Pro (å¯¦é©—æ€§)
    - æœ€æ–°çš„ Google AI æ¨¡å‹
    - æ›´å¼·çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›
    - æ›´è‡ªç„¶çš„èªè¨€è™•ç†
    - æ”¯æ´å¤šèªè¨€å„ªåŒ–
    - å¯¦é©—æ€§åŠŸèƒ½ï¼ŒæŒçºŒæ”¹é€²ä¸­
    """
}

# MarkItDown æœå‹™èªªæ˜
MARKITDOWN_SERVICE_INFO = """
### MarkItDown æ–‡ä»¶è½‰æ›å·¥å…·
- å°‡å„ç¨®æ ¼å¼çš„æ–‡ä»¶è½‰æ›ç‚º Markdown
- æ”¯æ´ PDFã€DOCXã€PowerPointã€Excel ç­‰æ ¼å¼
- å¯æå–é—œéµè©
"""

# åœ–ç‰‡åˆ†ææœå‹™èªªæ˜
IMAGE_ANALYSIS_SERVICE_INFO = """
### åœ–ç‰‡åˆ†æåŠŸèƒ½
- ä½¿ç”¨ OpenAI o4-mini æ¨¡å‹åˆ†æåœ–ç‰‡å…§å®¹
- å¯è¾¨è­˜åœ–ç‰‡æ–‡å­—å…§å®¹å’Œè¦–è¦ºå…ƒç´ 
- æ”¯æ´å„ç¨®åœ–ç‰‡æ ¼å¼ï¼ˆPNGã€JPG ç­‰ï¼‰
"""

# æ”¯æ´çš„æª”æ¡ˆé¡å‹
SUPPORTED_FILE_TYPES = [
    "pdf", "docx", "doc", "pptx", "ppt", 
    "xlsx", "xls", "csv", "txt", "rtf", 
    "html", "htm", "md", "markdown"
]

# æ”¯æ´çš„åœ–ç‰‡é¡å‹
SUPPORTED_IMAGE_TYPES = ["png", "jpg", "jpeg", "webp"]

def calculate_cost(input_tokens, output_tokens, model_name, is_cached=False):
    """è¨ˆç®— API ä½¿ç”¨æˆæœ¬
    
    Args:
        input_tokens (int): è¼¸å…¥ tokens æ•¸é‡
        output_tokens (int): è¼¸å‡º tokens æ•¸é‡
        model_name (str): æ¨¡å‹åç¨±
        is_cached (bool, optional): æ˜¯å¦ä½¿ç”¨å¿«å–è¼¸å…¥åƒ¹æ ¼. é è¨­ç‚º False
    
    Returns:
        tuple: (USD æˆæœ¬, NTD æˆæœ¬, è©³ç´°è¨ˆç®—è³‡è¨Š)
    """
    if model_name not in MODEL_CONFIG:
        return 0, 0, "æœªæ”¯æ´çš„æ¨¡å‹"
        
    # å–å¾—åƒ¹æ ¼è¨­å®š
    model = MODEL_CONFIG[model_name]
    input_price = model["cached_input"] if is_cached else model["input"]
    output_price = model["output"]
    
    # è¨ˆç®— USD æˆæœ¬ (ä»¥æ¯ 1M tokens ç‚ºå–®ä½)
    input_cost = (input_tokens / 1_000_000) * input_price
    output_cost = (output_tokens / 1_000_000) * output_price
    total_cost_usd = input_cost + output_cost
    total_cost_ntd = total_cost_usd * USD_TO_NTD
    
    # æº–å‚™è©³ç´°è¨ˆç®—è³‡è¨Š
    details = f"""
    è¨ˆç®—æ˜ç´° (USD):
    - è¼¸å…¥: {input_tokens:,} tokens Ã— ${input_price}/1M = ${input_cost:.4f}
    - è¼¸å‡º: {output_tokens:,} tokens Ã— ${output_price}/1M = ${output_cost:.4f}
    - ç¸½è¨ˆ (USD): ${total_cost_usd:.4f}
    - ç¸½è¨ˆ (NTD): NT${total_cost_ntd:.2f}
    """
    return total_cost_usd, total_cost_ntd, details

def refine_transcript_gemini(text, api_key, temperature=0.5, context=""):
    """ä½¿ç”¨ Gemini æ¨¡å‹å„ªåŒ–æ–‡å­—

    Args:
        text (str): è¦å„ªåŒ–çš„æ–‡å­—
        api_key (str): Gemini API é‡‘é‘°
        temperature (float): å‰µæ„ç¨‹åº¦ (0.0-1.0)
        context (str): ä¸Šä¸‹æ–‡æç¤º

    Returns:
        dict: åŒ…å«å„ªåŒ–å¾Œçš„æ–‡å­—å’Œæ‘˜è¦
    """
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-pro-exp-03-25')
        
        # æº–å‚™æç¤ºè©
        prompt = f"""
        è«‹å°‡ä»¥ä¸‹æ–‡å­—å„ªåŒ–ç‚ºä¸€ä»½çµæ§‹å®Œæ•´ã€æ ¼å¼è±å¯Œçš„æœƒè­°è¨˜éŒ„æˆ–è¬›ç¨¿è‰ç¨¿ã€‚
        ç„¡è«–è¼¸å…¥æ–‡å­—æ˜¯ç°¡é«”æˆ–ç¹é«”ä¸­æ–‡ï¼Œè«‹å‹™å¿…å°‡æ‰€æœ‰è¼¸å‡ºè½‰æ›ç‚ºç¹é«”ä¸­æ–‡ã€‚

        # ä»»å‹™è¦æ±‚
        1. **åŸºæœ¬è¦æ±‚**
           - å°‡æ‰€æœ‰æ–‡å­—è½‰æ›ç‚ºç¹é«”ä¸­æ–‡
           - ä¿æŒåŸæ„çš„æƒ…æ³ä¸‹è®“æ–‡å­—æ›´é€šé †ã€å°ˆæ¥­
           - è£½ä½œé‡é»æ‘˜è¦ï¼ˆ300å­—ä»¥å…§ï¼‰

        2. **æ ¼å¼è¦æ±‚**ï¼ˆè«‹åƒè€ƒä»¥ä¸‹ç¯„ä¾‹æ ¼å¼ï¼‰
           - ä½¿ç”¨ `---` ä½œç‚ºä¸»è¦åˆ†éš”ç·š
           - ä½¿ç”¨ `# ## ###` ç­‰æ¨™é¡Œå±¤ç´šå€åˆ†ä¸»é¡Œ
           - ä½¿ç”¨ `**ç²—é«”**` æ¨™ç¤ºï¼š
             * æ¨™é¡Œï¼ˆå¦‚ï¼š**æ¨™é¡Œï¼š**ï¼‰
             * è¬›è€…ï¼ˆå¦‚ï¼š**[è¬›è€…]:**ï¼‰
             * é—œéµè©æˆ–é‡è¦æ¦‚å¿µ
           - ä½¿ç”¨ `-` æˆ– `*` è£½ä½œé …ç›®æ¸…å–®ï¼Œæ”¯æ´å¤šå±¤ç¸®æ’
           - ä½¿ç”¨ `>` è£½ä½œå¼•ç”¨å€å¡Šï¼ˆé©ç”¨æ–¼é‡è¦å¼•è¿°ï¼‰
           - é©ç•¶ä½¿ç”¨ `*æ–œé«”*` å¼·èª¿æ¬¡è¦é‡é»

        # ä¸Šä¸‹æ–‡è³‡è¨Š
        {context if context else "ç„¡ç‰¹å®šä¸Šä¸‹æ–‡"}

        # åŸå§‹æ–‡å­—
        {text}

        # è«‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›æ‡‰ï¼ˆå¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼‰

        [å„ªåŒ–å¾Œæ–‡å­—]
        ---

        **(æœƒè­°è¨˜éŒ„/è¬›ç¨¿è‰ç¨¿ - è©³ç´°ç‰ˆ)**

        **æ¨™é¡Œï¼š** [ä¸»è¦æ¨™é¡Œ]

        **æ—¥æœŸï¼š** [æ—¥æœŸï¼Œè‹¥æœ‰]
        **åƒèˆ‡è€…ï¼š** [ç›¸é—œäººå“¡ï¼Œè‹¥æœ‰]

        ## 1. èƒŒæ™¯èªªæ˜
        **ä¸»è¦è­°é¡Œï¼š**
        - é‡é»ä¸€
          - ç´°ç¯€èªªæ˜
          - è£œå……è³‡è¨Š
        - é‡é»äºŒ
          - ç›¸é—œæ•¸æ“š
          - å…·é«”æ¡ˆä¾‹

        **[ç™¼è¨€è€…å§“å/è§’è‰²]:** ã€Œé‡è¦ç™¼è¨€å…§å®¹...ã€

        ## 2. è¨è«–å…§å®¹
        ### 2.1 è­°é¡Œæ¢è¨
        **ç¾æ³åˆ†æï¼š**
        - **ç›®å‰é€²åº¦ï¼š** èªªæ˜...
        - **é‡åˆ°æŒ‘æˆ°ï¼š**
          - æŒ‘æˆ°ä¸€
          - æŒ‘æˆ°äºŒ

        **è§£æ±ºæ–¹æ¡ˆï¼š**
        1. æ–¹æ¡ˆä¸€
           - å„ªé»ï¼š...
           - è€ƒé‡ï¼š...
        2. æ–¹æ¡ˆäºŒ
           - å»ºè­°åšæ³•ï¼š...
           - æ‰€éœ€è³‡æºï¼š...

        ### 2.2 æ±ºè­°äº‹é …
        **çµè«–ï¼š**
        - é‡è¦æ±ºå®šä¸€
        - é‡è¦æ±ºå®šäºŒ

        ## 3. å¾ŒçºŒè¦åŠƒ
        **æ™‚ç¨‹å®‰æ’ï¼š**
        - çŸ­æœŸç›®æ¨™ï¼ˆ1å€‹æœˆå…§ï¼‰
        - ä¸­æœŸç›®æ¨™ï¼ˆ3å€‹æœˆå…§ï¼‰
        - é•·æœŸç›®æ¨™ï¼ˆ6å€‹æœˆä»¥ä¸Šï¼‰

        **å¾…è¾¦äº‹é …ï¼š**
        1. å„ªå…ˆè™•ç†ï¼š...
        2. å¾ŒçºŒè¿½è¹¤ï¼š...

        ---

        [é‡é»æ‘˜è¦]
        ## æœƒè­°é‡é»æ‘˜è¦

        **æ ¸å¿ƒè­°é¡Œï¼š**
        1. ä¸»è¦è¨è«–é‡é»
           - é—œéµç™¼ç¾
           - é‡è¦æ±ºè­°
        
        **åŸ·è¡Œæ–¹å‘ï¼š**
        - è¿‘æœŸè¡Œå‹•é …ç›®
          - è² è²¬å–®ä½
          - æ™‚ç¨‹è¦åŠƒ
        
        **æ³¨æ„äº‹é …ï¼š**
        - éœ€è¦ç‰¹åˆ¥é—œæ³¨çš„è­°é¡Œ
        - æ½›åœ¨é¢¨éšªèˆ‡å› æ‡‰æªæ–½
        """
        
        response = model.generate_content(
            prompt,
            generation_config={
                'temperature': temperature
            }
        )
        
        # è§£æå›æ‡‰
        response_text = response.text
        
        # ä½¿ç”¨æ–°çš„åˆ†éš”æ–¹å¼è§£æå›æ‡‰
        if "[å„ªåŒ–å¾Œæ–‡å­—]" in response_text and "[é‡é»æ‘˜è¦]" in response_text:
            parts = response_text.split("[é‡é»æ‘˜è¦]")
            corrected = parts[0].split("[å„ªåŒ–å¾Œæ–‡å­—]")[1].strip()
            summary = parts[1].strip()
        else:
            # å¦‚æœæ‰¾ä¸åˆ°æ¨™è¨˜ï¼Œå˜—è©¦ä½¿ç”¨èˆŠçš„åˆ†éš”æ–¹å¼
            parts = response_text.split("é‡é»æ‘˜è¦ï¼š")
            if len(parts) >= 2:
                corrected = parts[0].strip()
                summary = parts[1].strip()
            else:
                corrected = response_text
                summary = "ç„¡æ³•ç”Ÿæˆæ‘˜è¦"
        
        return {
            "corrected": corrected,
            "summary": summary,
            "usage": {
                "total_input_tokens": 0,  # Gemini æš«æ™‚ä¸è¨ˆç®— tokens
                "total_output_tokens": 0
            }
        }
    except Exception as e:
        logger.error(f"Gemini API éŒ¯èª¤ï¼š{str(e)}")
        return None

def display_cost_info(
    input_tokens,
    output_tokens,
    model_name,
    is_cached=False
):
    """åœ¨ Streamlit ä»‹é¢ä¸­é¡¯ç¤ºæˆæœ¬è³‡è¨Š"""
    cost_usd, cost_ntd, details = calculate_cost(
        input_tokens,
        output_tokens,
        model_name,
        is_cached
    )
    
    with st.sidebar.expander("ğŸ’° æˆæœ¬è¨ˆç®—", expanded=True):
        st.write("### Token ä½¿ç”¨é‡")
        st.write(f"- è¼¸å…¥: {input_tokens:,} tokens")
        st.write(f"- è¼¸å‡º: {output_tokens:,} tokens")
        st.write(f"- ç¸½è¨ˆ: {input_tokens + output_tokens:,} tokens")
        
        if (input_tokens + output_tokens) == 0:
            st.warning("ç›®å‰ token ä½¿ç”¨é‡ç‚º 0ï¼Œè«‹ç¢ºèªæ˜¯å¦å·²æ­£ç¢ºè¨ˆç®— token æ•¸é‡ï¼")
        
        st.write("### è²»ç”¨æ˜ç´°")
        st.text(details)
        
        if is_cached:
            st.info("âœ¨ ä½¿ç”¨å¿«å–åƒ¹æ ¼è¨ˆç®—")

def process_markdown_extraction(text, api_key, model, keyword_count):
    """
    è™•ç† Markdown æ–‡æœ¬æå–é—œéµè©
    
    Args:
        text (str): Markdown æ–‡æœ¬
        api_key (str): OpenAI API Key
        model (str): æ¨¡å‹åç¨±
        keyword_count (int): è¦æå–çš„é—œéµè©æ•¸é‡
        
    Returns:
        List[str]: é—œéµè©åˆ—è¡¨
    """
    try:
        with st.spinner("æ­£åœ¨æå–é—œéµè©..."):
            keywords = extract_keywords(
                markdown_text=text,
                api_key=api_key,
                model=model,
                count=keyword_count
            )
            return keywords
    except Exception as e:
        st.error(f"æå–é—œéµè©å¤±æ•—: {str(e)}")
        logger.error(f"æå–é—œéµè©å¤±æ•—: {str(e)}")
        return []

def render_markitdown_tab_with_image_analysis():
    """æ¸²æŸ“æ•´åˆäº†åœ–ç‰‡åˆ†æåŠŸèƒ½çš„ MarkItDown æ¨™ç±¤é """
    st.header("Step 1: æ–‡ä»¶è½‰æ›èˆ‡åœ–ç‰‡åˆ†æ")
    
    # æ•´åˆçš„æœå‹™èªªæ˜
    combined_info = """
    ### æ–‡ä»¶èˆ‡åœ–ç‰‡åˆ†æå·¥å…·
    - å°‡å„ç¨®æ ¼å¼çš„æ–‡ä»¶è½‰æ›ç‚º Markdown
    - æ”¯æ´ PDFã€DOCXã€PowerPointã€Excel ç­‰æ ¼å¼
    - ä½¿ç”¨ OpenAI o4-mini æ¨¡å‹åˆ†ææ–‡ä»¶ä¸­çš„åœ–ç‰‡
    - æå–æ–‡å­—èˆ‡åœ–ç‰‡å…§å®¹ä½œç‚ºé—œéµè©å’Œä¸Šä¸‹æ–‡
    """
    st.markdown(combined_info)
    
    # åˆå§‹åŒ– session state
    if "markdown_text" not in st.session_state:
        st.session_state.markdown_text = None
    if "markdown_keywords" not in st.session_state:
        st.session_state.markdown_keywords = None
    if "analyzed_images" not in st.session_state:
        st.session_state.analyzed_images = {}
    if "combined_context" not in st.session_state:
        st.session_state.combined_context = None
    if "openai_api_key_checked" not in st.session_state:
        st.session_state.openai_api_key_checked = False

    # å¾å´é‚Šæ¬„ç²å– API é‡‘é‘°
    openai_api_key = st.session_state.get("openai_api_key", "")
    
    # è‹¥æœ‰ API é‡‘é‘°ï¼Œè¨­ç½®æ¨™è¨˜ä»¥é¿å…é‡è¤‡æª¢æŸ¥
    if openai_api_key and not st.session_state.openai_api_key_checked:
        st.session_state.openai_api_key_checked = True

    # å‰µå»ºå…©å€‹æ¨™ç±¤é ï¼šæ–‡ä»¶æˆ–åœ–ç‰‡ä¸Šå‚³å’Œä½¿ç”¨è€…è‡ªè¡Œè¼¸å…¥
    tab1, tab2 = st.tabs(["ğŸ“„ æ–‡ä»¶æˆ–åœ–ç‰‡ä¸Šå‚³", "âœï¸ ä½¿ç”¨è€…è‡ªè¡Œè¼¸å…¥"])
    
    # æ–‡ä»¶æˆ–åœ–ç‰‡ä¸Šå‚³æ¨™ç±¤é 
    with tab1:
        # åˆä½µæ”¯æ´çš„æª”æ¡ˆé¡å‹
        combined_file_types = SUPPORTED_FILE_TYPES + SUPPORTED_IMAGE_TYPES
        
        uploaded_files = st.file_uploader(
            "ä¸Šå‚³æ–‡ä»¶æˆ–åœ–ç‰‡",
            type=combined_file_types,
            accept_multiple_files=True,
            help="æ”¯æ´å¤šå€‹æª”æ¡ˆä¸Šå‚³ï¼ŒåŒ…å«æ–‡ä»¶åŠåœ–ç‰‡æ ¼å¼"
            )
            
        # å¢åŠ åœ–ç‰‡è™•ç†é¸é …
        enable_image_analysis = st.checkbox(
            "å•Ÿç”¨åœ–ç‰‡åˆ†æ",
            value=True,
            help="ä½¿ç”¨ OpenAI o4-mini æ¨¡å‹è‡ªå‹•åˆ†ææ–‡ä»¶ä¸­çš„åœ–ç‰‡å…§å®¹æˆ–åˆ†æä¸Šå‚³çš„åœ–ç‰‡"
        )
        
        # æª¢æŸ¥ API é‡‘é‘°ï¼Œåªæœ‰åœ¨æœªæª¢æŸ¥éä¸”æ²’æœ‰ API é‡‘é‘°æ™‚é¡¯ç¤ºè­¦å‘Š
        if enable_image_analysis and not openai_api_key and not st.session_state.openai_api_key_checked:
            st.warning("è«‹åœ¨å´é‚Šæ¬„å¡«å…¥ OpenAI API é‡‘é‘°ä»¥å•Ÿç”¨åœ–ç‰‡åˆ†æåŠŸèƒ½")
        
        if uploaded_files:
            # é¡¯ç¤ºä¸Šå‚³çš„æª”æ¡ˆæ•¸é‡
            st.info(f"å·²ä¸Šå‚³ {len(uploaded_files)} å€‹æª”æ¡ˆ")
            
            # å‰µå»ºä¸€å€‹å±•é–‹å€é¡¯ç¤ºæ‰€æœ‰ä¸Šå‚³çš„æª”æ¡ˆ
            with st.expander("æŸ¥çœ‹ä¸Šå‚³çš„æª”æ¡ˆæ¸…å–®", expanded=False):
                for i, file in enumerate(uploaded_files):
                    st.write(f"{i+1}. {file.name} ({file.size/1024:.1f} KB)")
            
            # è™•ç†æŒ‰éˆ•
            process_btn = st.button(
                f"ğŸ”„ è™•ç†æ‰€æœ‰æª”æ¡ˆ" + (" ä¸¦åˆ†æåœ–ç‰‡" if enable_image_analysis and openai_api_key else ""),
                use_container_width=True
            )
            
            if process_btn:
                # åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯ï¼ˆå¦‚æœå•Ÿç”¨äº†åœ–ç‰‡åˆ†æï¼‰
                if enable_image_analysis and openai_api_key:
                    client = OpenAI(api_key=openai_api_key)
                
                # è™•ç†æ¯å€‹æª”æ¡ˆ
                total_files = len(uploaded_files)
                progress_text = "æ­£åœ¨è™•ç†æª”æ¡ˆ..."
                progress_bar = st.progress(0, text=progress_text)
                
                combined_markdown = ""
                all_image_analysis_results = []
                total_input_tokens = 0
                total_output_tokens = 0
                
                for i, uploaded_file in enumerate(uploaded_files):
                    # æ›´æ–°é€²åº¦
                    progress = (i + 1) / total_files
                    progress_bar.progress(
                        progress,
                        text=f"{progress_text} ({i + 1}/{total_files}): {uploaded_file.name}"
                    )
                    
                    # åˆ¤æ–·æª”æ¡ˆé¡å‹
                    file_extension = uploaded_file.name.split('.')[-1].lower()
                    is_image = file_extension in SUPPORTED_IMAGE_TYPES
                    
                    # ä¿å­˜ä¸Šå‚³çš„æª”æ¡ˆ
                    with tempfile.NamedTemporaryFile(
                        delete=False, 
                        suffix=f".{file_extension}"
                    ) as temp_file:
                        temp_file.write(uploaded_file.getvalue())
                        temp_path = temp_file.name
                    
                    # æ ¹æ“šæª”æ¡ˆé¡å‹é€²è¡Œè™•ç†
                    if is_image and enable_image_analysis and openai_api_key:
                        # è™•ç†åœ–ç‰‡æ–‡ä»¶
                        with st.spinner(f"åˆ†æåœ–ç‰‡ {i + 1}/{total_files}: {uploaded_file.name}"):
                            try:
                                # åˆ†æåœ–ç‰‡
                                result = analyze_image(client, temp_path)
                                
                                if result["success"]:
                                    image_name = uploaded_file.name
                                    st.session_state.analyzed_images[image_name] = {
                                        "path": temp_path,
                                        "result": result["result"],
                                        "usage": result["usage"]
                                    }
                                    
                                    # æ›´æ–° token ä½¿ç”¨é‡
                                    if "usage" in result:
                                        total_input_tokens += result["usage"].get(
                                            "input_tokens", 0
                                        )
                                        total_output_tokens += result["usage"].get(
                                            "output_tokens", 0
                                        )
                                    
                                    # å°‡åœ–ç‰‡åˆ†æçµæœæ·»åŠ åˆ°åˆä½µçš„ Markdown ä¸­
                                    image_markdown = f"""
# åœ–ç‰‡åˆ†æçµæœ: {image_name}

![{image_name}]({temp_path})

## åˆ†æå…§å®¹
{result["result"]}

---

"""
                                    combined_markdown += image_markdown
                                    all_image_analysis_results.append(result["result"])
                                else:
                                    st.error(f"åœ–ç‰‡ {uploaded_file.name} åˆ†æå¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
                            except Exception as e:
                                st.error(f"è™•ç†åœ–ç‰‡ {uploaded_file.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                    elif not is_image:
                        # è™•ç†æ–‡ä»¶
                        with st.spinner(f"è½‰æ›æ–‡ä»¶ {i + 1}/{total_files}: {uploaded_file.name}"):
                            try:
                                success, md_text, info = convert_file_to_markdown(
                                    input_path=temp_path,
                                    use_llm=False,
                                    api_key=openai_api_key,
                                    model="o4-mini"
                                )
                                
                                if success:
                                    # å¦‚æœå•Ÿç”¨äº†åœ–ç‰‡åˆ†æï¼Œå‰‡åˆ†ææ–‡ä»¶ä¸­çš„åœ–ç‰‡
                                    if enable_image_analysis and openai_api_key:
                                        # å¾ md_text ä¸­æå–åœ–ç‰‡è·¯å¾‘
                                        image_paths = extract_image_paths_from_markdown(
                                            md_text, 
                                            os.path.dirname(temp_path)
                                        )
                                        
                                        if image_paths:
                                            st.info(
                                                f"å¾æ–‡ä»¶ {uploaded_file.name} ä¸­æ‰¾åˆ° {len(image_paths)} å¼µåœ–ç‰‡ï¼Œé–‹å§‹åˆ†æ..."
                                            )
                                            
                                            # åˆ†ææ¯å¼µåœ–ç‰‡
                                            file_image_results = []
                                            
                                            for img_path in image_paths:
                                                try:
                                                    img_result = analyze_image(client, img_path)
                                                    if img_result["success"]:
                                                        image_name = os.path.basename(img_path)
                                                        st.session_state.analyzed_images[image_name] = {
                                                            "path": img_path,
                                                            "result": img_result["result"],
                                                            "usage": img_result["usage"]
                                                        }
                                                        # æ›´æ–° token ä½¿ç”¨é‡
                                                        if "usage" in img_result:
                                                            total_input_tokens += img_result["usage"].get(
                                                                "input_tokens", 0
                                                            )
                                                            total_output_tokens += img_result["usage"].get(
                                                                "output_tokens", 0
                                                            )
                                                        file_image_results.append(img_result["result"])
                                                        all_image_analysis_results.append(img_result["result"])
                                                except Exception as e:
                                                    st.error(f"åœ–ç‰‡åˆ†æå¤±æ•—: {str(e)}")
                    
                                            # å°‡åœ–ç‰‡åˆ†æçµæœæ·»åŠ åˆ° Markdown ä¸­
                                            if file_image_results:
                                                md_text = add_image_analysis_to_markdown(
                                                    md_text, 
                                                    image_paths, 
                                                    file_image_results
                                                )
                                    
                                    # æ·»åŠ æ–‡ä»¶æ¨™é¡Œå’Œåˆ†éš”ç·š
                                    file_markdown = f"""
# æ–‡ä»¶: {uploaded_file.name}

{md_text}

---

"""
                                    combined_markdown += file_markdown
                            else:
                                st.error(f"æ–‡ä»¶ {uploaded_file.name} è½‰æ›å¤±æ•—: {info.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
                            except Exception as e:
                                st.error(f"è™•ç†æ–‡ä»¶ {uploaded_file.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                    
                    # æ¸…ç†è‡¨æ™‚æª”æ¡ˆï¼ˆé™¤éæ˜¯åœ–ç‰‡ï¼Œåœ–ç‰‡ä¿ç•™ä»¥ä¾¿é¡¯ç¤ºï¼‰
                    if not is_image:
                        try:
                            os.remove(temp_path)
                        except Exception as e:
                            logger.error(f"æ¸…ç†è‡¨æ™‚æª”æ¡ˆå¤±æ•—: {str(e)}")
        
                # å®Œæˆè™•ç†æ‰€æœ‰æª”æ¡ˆ
                progress_bar.empty()
                
                if combined_markdown:
                    st.success(f"å·²å®Œæˆ {total_files} å€‹æª”æ¡ˆçš„è™•ç†")
        
                    # å„²å­˜çµæœåˆ° session state
                    st.session_state.markdown_text = combined_markdown
                    
                    # å»ºç«‹åˆä½µçš„ä¸Šä¸‹æ–‡
                    if all_image_analysis_results:
                        st.session_state.combined_context = f"""
æ–‡ä»¶æ–‡å­—å…§å®¹ï¼š
{combined_markdown}

åœ–ç‰‡åˆ†æçµæœï¼š
{' '.join(all_image_analysis_results)}
"""
                                else:
                        st.session_state.combined_context = combined_markdown
                    
                    # é¡¯ç¤º token ä½¿ç”¨é‡
                    if total_input_tokens > 0 or total_output_tokens > 0:
                        with st.expander("Token ä½¿ç”¨é‡", expanded=True):
                            st.write(f"è¼¸å…¥ Tokens: {total_input_tokens:,}")
                            st.write(f"è¼¸å‡º Tokens: {total_output_tokens:,}")
                            st.write(
                                f"ç¸½è¨ˆ Tokens: {total_input_tokens + total_output_tokens:,}"
                            )
                            
                            # è¨ˆç®—è²»ç”¨
                            cost_usd, cost_ntd, _ = calculate_cost(
                                total_input_tokens,
                                total_output_tokens,
                                "o4-mini",
                                is_cached=False
                            )
                            st.write(
                                f"ä¼°è¨ˆè²»ç”¨: USD ${cost_usd:.4f} (NTD ${cost_ntd:.2f})"
                            )
                    
                    # è‡ªå‹•æå–é—œéµè©
                    if openai_api_key:
                        with st.spinner("æ­£åœ¨æå–é—œéµè©..."):
                            keywords = extract_keywords(
                                markdown_text=st.session_state.combined_context,
                                api_key=openai_api_key,
                                model="o4-mini",
                                count=15
                            )
                            
                            if keywords:
                                st.session_state.markdown_keywords = keywords
                                st.success(f"å·²è‡ªå‹•æå– {len(keywords)} å€‹é—œéµè©")
        
                                # é¡¯ç¤ºé—œéµè©
                                with st.expander("æå–çš„é—œéµè©", expanded=True):
                                    st.write(", ".join(keywords))
                    
                    # é¡¯ç¤º Markdown å…§å®¹
                    with st.expander("åˆä½µçš„ Markdown å…§å®¹", expanded=True):
                st.text_area(
                            "è™•ç†çµæœ",
                            st.session_state.markdown_text,
                            height=300
                )
                
                        # ä¸‹è¼‰æŒ‰éˆ•
                    st.download_button(
                            label="ğŸ“¥ ä¸‹è¼‰ Markdown æª”æ¡ˆ",
                            data=st.session_state.markdown_text,
                            file_name="combined.md",
                        mime="text/markdown",
                            help="ä¸‹è¼‰åˆä½µå¾Œçš„ Markdown æ–‡ä»¶"
                    )
                
                    # è‡ªå‹•å‚³å…¥ä¸‹ä¸€æ­¥é©Ÿ
                    st.session_state.transcribed_text = st.session_state.markdown_text
                    
                    # é¡¯ç¤ºå·²è‡ªå‹•å‚³å…¥è¨Šæ¯
                    st.success("âœ… è™•ç†çµæœå·²è‡ªå‹•å‚³å…¥ Step 3: æ–‡å­—å„ªåŒ–")
                else:
                    st.warning("æ‰€æœ‰æª”æ¡ˆè™•ç†å®Œæˆï¼Œä½†æœªç”Ÿæˆæœ‰æ•ˆçš„ Markdown å…§å®¹")
                    
                # æ¸…ç†ä¸Šå‚³æª”æ¡ˆè¨˜éŒ„ï¼Œè®“ä½¿ç”¨è€…å¯ä»¥ä¸Šå‚³æ–°æª”æ¡ˆ
                st.rerun()

    # ä½¿ç”¨è€…è‡ªè¡Œè¼¸å…¥æ¨™ç±¤é 
    with tab2:
        user_text = st.text_area(
            "ç›´æ¥è¼¸å…¥æ–‡å­—",
            placeholder="åœ¨æ­¤è¼¸å…¥æ‚¨çš„æ–‡å­—å…§å®¹...",
            help="ç›´æ¥è¼¸å…¥è¦è™•ç†çš„æ–‡å­—å…§å®¹",
                    height=300
                )
                
        if user_text:
            # è™•ç†æŒ‰éˆ•
            process_text_btn = st.button(
                "âœ… è™•ç†æ–‡å­—å…§å®¹",
                use_container_width=True
            )
            
            if process_text_btn:
                # å„²å­˜ç”¨æˆ¶è¼¸å…¥çš„æ–‡å­—
                st.session_state.markdown_text = user_text
                
                # è‡ªå‹•æå–é—œéµè©
                if openai_api_key:
                    with st.spinner("æ­£åœ¨æå–é—œéµè©..."):
                        keywords = extract_keywords(
                            markdown_text=user_text,
                                    api_key=openai_api_key,
                            model="o4-mini",
                            count=15
                        )
                        
                        if keywords:
                            st.session_state.markdown_keywords = keywords
                            st.success(f"å·²è‡ªå‹•æå– {len(keywords)} å€‹é—œéµè©")
                            
                            # é¡¯ç¤ºé—œéµè©
                            with st.expander("æå–çš„é—œéµè©", expanded=True):
                                st.write(", ".join(keywords))
                
                st.success(
                    f"æ–‡å­—å…§å®¹å·²è™•ç†ï¼é•·åº¦: {len(user_text)} å­—å…ƒ"
                )
                
                # è‡ªå‹•å‚³å…¥ä¸‹ä¸€æ­¥é©Ÿ
                st.session_state.transcribed_text = user_text
                
                # é¡¯ç¤ºå·²è‡ªå‹•å‚³å…¥è¨Šæ¯
                st.success("âœ… è™•ç†çµæœå·²è‡ªå‹•å‚³å…¥ Step 3: æ–‡å­—å„ªåŒ–")
                
                # æ¸…ç†è¼¸å…¥æ¡†
                                st.rerun()

    # ç§»é™¤ç¨ç«‹çš„åœ–ç‰‡åˆ†ææ¨™ç±¤é ä»£ç¢¼
    # with main_tabs[3]:
    #     render_image_analysis_tab()

    # ç§»é™¤é—œæ–¼æ¨™ç±¤é çš„å…§å®¹ï¼Œæ”¹ç‚ºåœ¨å´é‚Šæ¬„é¡¯ç¤º
    with st.sidebar:
        # åˆ†éš”ç·š
        st.markdown("---")
        
        # é—œæ–¼è³‡è¨Š
        with st.expander("â„¹ï¸ é—œæ–¼", expanded=False):
            st.markdown("""
            ### éŸ³è¨Šè½‰æ–‡å­—èˆ‡æ–‡ä»¶è™•ç†ç³»çµ±
            
            æœ¬ç³»çµ±æä¾›ä»¥ä¸‹åŠŸèƒ½ï¼š
            
            1. **æ–‡ä»¶è½‰æ›èˆ‡é—œéµè©**ï¼šå°‡å„ç¨®æ ¼å¼æ–‡ä»¶è½‰ç‚º Markdown
            2. **èªéŸ³è½‰æ–‡å­—**ï¼šå°‡éŸ³è¨Šæª”æ¡ˆè½‰æ›ç‚ºæ–‡å­—
            3. **æ–‡å­—å„ªåŒ–**ï¼šå„ªåŒ–è½‰éŒ„æ–‡å­—ï¼Œè£½ä½œæœƒè­°è¨˜éŒ„æˆ–è¬›ç¨¿
            
            ### æŠ€è¡“æ”¯æ´
            * éŸ³è¨Šè½‰æ–‡å­—ï¼šOpenAI æ¨¡å‹ã€Whisper æ¨¡å‹
            * æ–‡å­—å„ªåŒ–ï¼šGPT-4o ç³»åˆ—æ¨¡å‹ã€Gemini 2.5 Pro
            * æ–‡ä»¶è½‰æ›ï¼šMarkItDown å¥—ä»¶
            
            ### ç‰ˆæœ¬è³‡è¨Š
            * ç‰ˆæœ¬ï¼š1.1.0
            * æ›´æ–°æ—¥æœŸï¼š2025-04-20
            * æ–°å¢åŠŸèƒ½ï¼šæ–‡ä»¶è½‰æ›èˆ‡é—œéµè©æå–
            """)


if __name__ == "__main__":
    main() 