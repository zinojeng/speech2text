"""
æä¾› MarkItDown ç›¸é—œåŠŸèƒ½çš„å¯¦ç”¨å‡½æ•¸
"""

import os
import tempfile
from pathlib import Path
import logging
from markitdown import MarkItDown
from openai import OpenAI, AuthenticationError
from typing import Dict, Any, Optional, List, Tuple
import subprocess
import sys
import base64
from io import BytesIO

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("markitdown-utils")


def reinstall_magika():
    """é‡æ–°å®‰è£ magika å¥—ä»¶ä»¥ä¿®å¾©æå£çš„æ¨¡å‹æª”æ¡ˆ"""
    try:
        logger.info("å˜—è©¦é‡æ–°å®‰è£ magika å¥—ä»¶...")
        subprocess.check_call([
            sys.executable, "-m", "pip", "uninstall", "magika", "-y"
        ])
        subprocess.check_call([
            sys.executable, "-m", "pip", "install", "magika"
        ])
        logger.info("magika å¥—ä»¶é‡æ–°å®‰è£å®Œæˆ")
        return True
    except Exception as e:
        logger.error(f"é‡æ–°å®‰è£ magika å¤±æ•—: {e}")
        return False


def convert_file_to_markdown(input_path: str,
                             use_llm: bool = False,
                             api_key: Optional[str] = None,
                             model: str = "gpt-4o") -> Tuple[bool, str,
                                                             Dict[str, Any]]:
    """
    å°‡æª”æ¡ˆè½‰æ›ç‚º Markdown æ ¼å¼ï¼Œå¯é¸ç”¨ LLM è™•ç†åœ–ç‰‡
    
    Args:
        input_path (str): è¼¸å…¥æª”æ¡ˆè·¯å¾‘
        use_llm (bool): æ˜¯å¦ä½¿ç”¨ LLM è™•ç†åœ–ç‰‡
        api_key (str, optional): OpenAI API Key
        model (str): OpenAI æ¨¡å‹åç¨±
    
    Returns:
        Tuple[bool, str, Dict]: (æ˜¯å¦æˆåŠŸ, Markdown æ–‡å­—, è½‰æ›è³‡è¨Š)
    """
    try:
        input_path = Path(input_path).resolve()
        
        if not input_path.exists():
            logger.error(f"æ‰¾ä¸åˆ°æª”æ¡ˆ: {input_path}")
            return False, "", {"error": f"æ‰¾ä¸åˆ°æª”æ¡ˆ: {input_path}"}
            
        logger.info(f"æ­£åœ¨è½‰æ›: {input_path}")
        
        # æª¢æŸ¥æ˜¯å¦ç‚º PPTX æª”æ¡ˆï¼Œå¦‚æœæ˜¯å‰‡ä½¿ç”¨æ›¿ä»£æ–¹æ³•
        if str(input_path).lower().endswith('.pptx'):
            logger.info("åµæ¸¬åˆ° PPTX æª”æ¡ˆï¼Œä½¿ç”¨æ›¿ä»£è½‰æ›æ–¹æ³•...")
            
            # å¦‚æœå•Ÿç”¨ LLM ä¸”æœ‰ API Keyï¼Œå„ªå…ˆä½¿ç”¨ Vision API æ–¹æ¡ˆ
            if use_llm and api_key:
                try:
                    from alternative_pptx_converter import analyze_pptx_with_vision
                    logger.info("å˜—è©¦ä½¿ç”¨ Vision API åˆ†æ PPTX...")
                    
                    success, result_text, vision_info = analyze_pptx_with_vision(
                        str(input_path), api_key, model
                    )
                    
                    if success and result_text:
                        conversion_info = {
                            "method": "vision_api",
                            "file_name": input_path.name,
                            "file_size": input_path.stat().st_size,
                            **vision_info
                        }
                        logger.info(f"æˆåŠŸä½¿ç”¨ Vision API åˆ†æ PPTXï¼Œå…§å®¹é•·åº¦: {len(result_text)}")
                        return True, result_text, conversion_info
                    else:
                        logger.warning("Vision API åˆ†æå¤±æ•—ï¼Œå›é€€åˆ° python-pptx æ–¹æ³•")
                        
                except ImportError:
                    logger.warning("æ‰¾ä¸åˆ° alternative_pptx_converter æ¨¡çµ„ï¼Œä½¿ç”¨ python-pptx æ–¹æ³•")
                except Exception as e:
                    logger.warning(f"Vision API åˆ†æå‡ºéŒ¯: {e}ï¼Œä½¿ç”¨ python-pptx æ–¹æ³•")
            
            # å›é€€åˆ°åŸæœ¬çš„ python-pptx æ–¹æ³•
            try:
                # å˜—è©¦ä½¿ç”¨ python-pptx ç›´æ¥è½‰æ›
                from pptx import Presentation
                
                prs = Presentation(str(input_path))
                text_content = []
                slide_count = 0
                
                for slide_idx, slide in enumerate(prs.slides, 1):
                    slide_count += 1
                    text_content.append(f"\n## æŠ•å½±ç‰‡ {slide_idx}\n")
                    
                    slide_has_content = False
                    
                    for shape in slide.shapes:
                        # æª¢æŸ¥æ–‡å­—å…§å®¹
                        if hasattr(shape, "text") and shape.text and shape.text.strip():
                            text_content.append(shape.text.strip())
                            text_content.append("")
                            slide_has_content = True
                        
                        # æª¢æŸ¥æ–‡å­—æ¡†å…§çš„æ®µè½
                        if hasattr(shape, "text_frame") and shape.text_frame:
                            for paragraph in shape.text_frame.paragraphs:
                                para_text = paragraph.text.strip()
                                if para_text:
                                    text_content.append(para_text)
                                    text_content.append("")
                                    slide_has_content = True
                        
                        # æª¢æŸ¥è¡¨æ ¼
                        if hasattr(shape, 'has_table') and shape.has_table:
                            text_content.append("\n### è¡¨æ ¼\n")
                            table = shape.table
                            for row_idx, row in enumerate(table.rows):
                                row_text = []
                                for cell in row.cells:
                                    cell_text = cell.text.strip().replace("|", "\\|")
                                    row_text.append(cell_text)
                                text_content.append("| " + " | ".join(row_text) + " |")
                                if row_idx == 0:
                                    separator = "|" + "|".join([" --- " for _ in row.cells]) + "|"
                                    text_content.append(separator)
                            text_content.append("")
                            slide_has_content = True
                    
                    # å¦‚æœæŠ•å½±ç‰‡æ²’æœ‰æ–‡å­—å…§å®¹ï¼Œæª¢æŸ¥æ˜¯å¦æœ‰åœ–ç‰‡ä¸¦ä½¿ç”¨ Vision API
                    if not slide_has_content:
                        image_analyzed = False
                        
                        # å¦‚æœå•Ÿç”¨äº† LLM ä¸”æœ‰ API Keyï¼Œå˜—è©¦åˆ†æåœ–ç‰‡
                        if use_llm and api_key:
                            try:
                                # æå–æŠ•å½±ç‰‡ç‚ºåœ–ç‰‡
                                slide_image_path = extract_slide_as_image(prs, slide_idx - 1, input_path)
                                if slide_image_path:
                                    # ä½¿ç”¨ OpenAI Vision åˆ†æåœ–ç‰‡
                                    vision_result = analyze_slide_image(slide_image_path, api_key, model)
                                    if vision_result:
                                        text_content.append("### ğŸ” åœ–ç‰‡å…§å®¹åˆ†æ")
                                        text_content.append(vision_result)
                                        text_content.append("")
                                        image_analyzed = True
                                        slide_has_content = True
                                    
                                    # æ¸…ç†è‡¨æ™‚åœ–ç‰‡æª”æ¡ˆ
                                    try:
                                        os.remove(slide_image_path)
                                    except:
                                        pass
                            except Exception as e:
                                logger.warning(f"åˆ†ææŠ•å½±ç‰‡ {slide_idx} åœ–ç‰‡æ™‚å‡ºéŒ¯: {e}")
                        
                        # å¦‚æœæ²’æœ‰åˆ†æåœ–ç‰‡æˆ–åˆ†æå¤±æ•—ï¼Œæ·»åŠ é è¨­æç¤º
                        if not image_analyzed:
                            text_content.append("*æ­¤æŠ•å½±ç‰‡ç„¡æ–‡å­—å…§å®¹æˆ–ç‚ºåœ–ç‰‡æŠ•å½±ç‰‡*")
                            text_content.append("")
                
                result_text = "\n".join(text_content)
                
                conversion_info = {
                    "method": "python-pptx",
                    "file_name": input_path.name,
                    "file_size": input_path.stat().st_size,
                    "slide_count": slide_count,
                    "content_length": len(result_text)
                }
                
                logger.info(f"æˆåŠŸä½¿ç”¨ python-pptx è½‰æ› {slide_count} å¼µæŠ•å½±ç‰‡ï¼Œå…§å®¹é•·åº¦: {len(result_text)}")
                
                # å¦‚æœçµæœç‚ºç©ºæˆ–éçŸ­ï¼Œè¨˜éŒ„è­¦å‘Š
                if len(result_text.strip()) < 50:
                    logger.warning(f"è½‰æ›çµæœå¯èƒ½ç‚ºç©ºæˆ–éçŸ­ï¼Œå…§å®¹é è¦½: {repr(result_text[:100])}")
                
                return True, result_text, conversion_info
                
            except ImportError:
                logger.warning("æœªå®‰è£ python-pptxï¼Œå˜—è©¦ä½¿ç”¨ MarkItDown...")
            except Exception as e:
                logger.warning(f"python-pptx è½‰æ›å¤±æ•—: {e}ï¼Œå˜—è©¦ä½¿ç”¨ MarkItDown...")
        
        # å»ºç«‹ MarkItDown å¯¦ä¾‹
        md_kwargs = {"enable_plugins": True}
        llm_client = None
        llm_info = {}
        
        if use_llm:
            logger.info(f"å˜—è©¦å•Ÿç”¨ LLM ({model}) é€²è¡Œè™•ç†...")
            current_api_key = api_key or os.environ.get("OPENAI_API_KEY")
            if not current_api_key:
                logger.warning("æœªæä¾› OpenAI API Keyï¼Œç„¡æ³•ä½¿ç”¨ LLM è™•ç†åœ–ç‰‡ã€‚")
                llm_info["status"] = "æœªæä¾› API Key"
            else:
                try:
                    llm_client = OpenAI(api_key=current_api_key)
                    # åŸ·è¡Œä¸€å€‹ç°¡å–®çš„æ¸¬è©¦å‘¼å«ä¾†é©—è­‰é‡‘é‘°
                    llm_client.models.list() 
                    logger.info("OpenAI API Key é©—è­‰æˆåŠŸã€‚")
                    md_kwargs["llm_client"] = llm_client
                    md_kwargs["llm_model"] = model
                    llm_info["status"] = "å•Ÿç”¨æˆåŠŸ"
                    llm_info["model"] = model
                except AuthenticationError:
                    logger.error("OpenAI API Key ç„¡æ•ˆæˆ–éŒ¯èª¤ï¼Œç„¡æ³•ä½¿ç”¨ LLMã€‚")
                    llm_info["status"] = "API Key ç„¡æ•ˆ"
                except Exception as e:
                    logger.error(f"åˆå§‹åŒ– OpenAI client æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    llm_info["status"] = f"åˆå§‹åŒ–éŒ¯èª¤: {str(e)}"

        # å˜—è©¦å»ºç«‹ MarkItDown å¯¦ä¾‹ï¼Œå¦‚æœå¤±æ•—å‰‡å˜—è©¦ä¿®å¾©
        max_retries = 2
        md = None
        
        for attempt in range(max_retries):
            try:
                md = MarkItDown(**md_kwargs)
                break
            except Exception as e:
                error_msg = str(e)
                logger.error(f"å»ºç«‹ MarkItDown å¯¦ä¾‹å¤±æ•— "
                           f"(å˜—è©¦ {attempt + 1}/{max_retries}): {error_msg}")
                
                # æª¢æŸ¥æ˜¯å¦ç‚º magika ç›¸é—œéŒ¯èª¤
                if ("magika" in error_msg.lower() and 
                    "json" in error_msg.lower()):
                    if attempt == 0:  # ç¬¬ä¸€æ¬¡å˜—è©¦ä¿®å¾©
                        logger.info("åµæ¸¬åˆ° magika å¥—ä»¶å•é¡Œï¼Œå˜—è©¦ä¿®å¾©...")
                        if reinstall_magika():
                            continue
                    
                    # å¦‚æœä¿®å¾©å¤±æ•—æˆ–æ˜¯ç¬¬äºŒæ¬¡å˜—è©¦ï¼Œä½¿ç”¨ä¸ä¾è³´ magika çš„æ–¹å¼
                    logger.warning("ä½¿ç”¨ç°¡åŒ–æ¨¡å¼ï¼Œä¸ä½¿ç”¨æª”æ¡ˆé¡å‹åµæ¸¬")
                    try:
                        # å˜—è©¦ä¸ä½¿ç”¨ magika çš„æ–¹å¼
                        md_kwargs_simple = {}
                        if llm_client:
                            md_kwargs_simple["llm_client"] = llm_client
                            md_kwargs_simple["llm_model"] = model
                        md = MarkItDown(**md_kwargs_simple)
                        break
                    except Exception as e2:
                        logger.error(f"ç°¡åŒ–æ¨¡å¼ä¹Ÿå¤±æ•—: {e2}")
                        if attempt == max_retries - 1:
                            raise e
                else:
                    if attempt == max_retries - 1:
                        raise e
        
        if md is None:
            raise Exception("ç„¡æ³•å»ºç«‹ MarkItDown å¯¦ä¾‹")
        
        # è½‰æ›æª”æ¡ˆ
        result = md.convert(str(input_path))
        
        # æº–å‚™è½‰æ›è³‡è¨Š
        conversion_info = {
            "llm": llm_info,
            "file_name": input_path.name,
            "file_size": input_path.stat().st_size
        }
        
        if result and result.text_content:
            # æª¢æŸ¥ converter_used å±¬æ€§æ˜¯å¦å­˜åœ¨
            if hasattr(result, 'converter_used'):
                conversion_info["converter"] = result.converter_used
            conversion_info["content_length"] = len(result.text_content)
            
            return True, result.text_content, conversion_info
        else:
            logger.error("è½‰æ›å¤±æ•—ï¼Œæœªç²å¾—æœ‰æ•ˆçµæœ")
            return False, "", {"error": "è½‰æ›å¤±æ•—ï¼Œæœªç²å¾—æœ‰æ•ˆçµæœ"}
            
    except Exception as e:
        logger.error(f"è½‰æ›éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        error_details = traceback.format_exc()
        logger.error(error_details)
        return False, "", {"error": str(e), "details": error_details}

def convert_url_to_markdown(url: str) -> Tuple[bool, str, Dict[str, Any]]:
    """
    å°‡ URL è½‰æ›ç‚º Markdown æ ¼å¼
    
    Args:
        url (str): è¼¸å…¥ URL
    
    Returns:
        Tuple[bool, str, Dict]: (æ˜¯å¦æˆåŠŸ, Markdown æ–‡å­—, è½‰æ›è³‡è¨Š)
    """
    try:
        logger.info(f"æ­£åœ¨è½‰æ› URL: {url}")
        
        # å»ºç«‹ MarkItDown å¯¦ä¾‹
        md = MarkItDown(enable_plugins=True)
        
        # è½‰æ› URL
        result = md.convert(url)
        
        # æº–å‚™è½‰æ›è³‡è¨Š
        conversion_info = {
            "url": url
        }
        
        if result and result.text_content:
            # æª¢æŸ¥ converter_used å±¬æ€§æ˜¯å¦å­˜åœ¨
            if hasattr(result, 'converter_used'):
                conversion_info["converter"] = result.converter_used
            conversion_info["content_length"] = len(result.text_content)
            
            return True, result.text_content, conversion_info
        else:
            logger.error("è½‰æ›å¤±æ•—ï¼Œæœªç²å¾—æœ‰æ•ˆçµæœ")
            return False, "", {"error": "è½‰æ›å¤±æ•—ï¼Œæœªç²å¾—æœ‰æ•ˆçµæœ"}
            
    except Exception as e:
        logger.error(f"è½‰æ›éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        error_details = traceback.format_exc()
        logger.error(error_details)
        return False, "", {"error": str(e), "details": error_details}

def extract_keywords(markdown_text: str, api_key: str, model: str = "gpt-4o-mini", count: int = 10) -> List[str]:
    """
    å¾ Markdown æ–‡å­—ä¸­æå–é—œéµè©
    
    Args:
        markdown_text (str): Markdown æ ¼å¼çš„æ–‡å­—
        api_key (str): OpenAI API Key
        model (str): æ¨¡å‹åç¨±
        count (int): è¦æå–çš„é—œéµè©æ•¸é‡
    
    Returns:
        List[str]: é—œéµè©åˆ—è¡¨
    """
    try:
        client = OpenAI(api_key=api_key)
        
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "system", 
                    "content": f"ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„é—œéµè©æå–å·¥å…·ã€‚è«‹å¾æä¾›çš„æ–‡æœ¬ä¸­æå–æœ€é‡è¦çš„ {count} å€‹é—œéµè©æˆ–çŸ­èªï¼Œé€™äº›è©èªèƒ½å¤ åæ˜ æ–‡æœ¬çš„æ ¸å¿ƒä¸»é¡Œã€æ¦‚å¿µå’Œå°ˆæ¥­è¡“èªã€‚é—œéµè©æ‡‰ä»¥ç¹é«”ä¸­æ–‡æä¾›ï¼Œä¸¦æŒ‰é‡è¦æ€§æ’åºã€‚è«‹åƒ…è¿”å›é—œéµè©åˆ—è¡¨ï¼Œä¸€è¡Œä¸€å€‹é—œéµè©ï¼Œä¸è¦åŠ ç·¨è™Ÿæˆ–ä»»ä½•å…¶ä»–èªªæ˜ã€‚"
                },
                {
                    "role": "user",
                    "content": markdown_text
                }
            ],
            temperature=0.3
        )
        
        keywords_text = response.choices[0].message.content
        
        # è™•ç†å›æ‡‰ï¼Œå°‡æ–‡å­—åˆ†å‰²æˆåˆ—è¡¨
        keywords = [kw.strip() for kw in keywords_text.strip().split('\n') if kw.strip()]
        
        return keywords
        
    except Exception as e:
        logger.error(f"æå–é—œéµè©å¤±æ•—: {e}")
        return []

def save_uploaded_file(uploaded_file) -> Tuple[bool, str]:
    """
    å°‡ä¸Šå‚³çš„æª”æ¡ˆä¿å­˜åˆ°è‡¨æ™‚ç›®éŒ„
    
    Args:
        uploaded_file: Streamlit ä¸Šå‚³çš„æª”æ¡ˆç‰©ä»¶
        
    Returns:
        Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, è‡¨æ™‚æª”æ¡ˆè·¯å¾‘)
    """
    try:
        # å–å¾—æª”æ¡ˆå¾Œç¶´
        file_extension = os.path.splitext(uploaded_file.name)[1]
        
        # å‰µå»ºè‡¨æ™‚æª”æ¡ˆ
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp:
            temp.write(uploaded_file.getbuffer())
            return True, temp.name
    except Exception as e:
        logger.error(f"ä¿å­˜ä¸Šå‚³æª”æ¡ˆå¤±æ•—: {e}")
        return False, str(e) 

def convert_images_to_markdown(
    image_paths: List[str],
    output_file: str,
    title: str = "åœ–ç‰‡é›†åˆ",
    use_llm: bool = True,
    api_key: Optional[str] = None,
    model: str = "gpt-4o-mini"
) -> Tuple[bool, str, Dict[str, Any]]:
    """
    å°‡å¤šå€‹åœ–ç‰‡æª”æ¡ˆè½‰æ›ç‚ºå–®ä¸€ Markdown æª”æ¡ˆ
    
    Args:
        image_paths (List[str]): åœ–ç‰‡æª”æ¡ˆè·¯å¾‘åˆ—è¡¨
        output_file (str): è¼¸å‡º Markdown æª”æ¡ˆè·¯å¾‘
        title (str): Markdown æ–‡ä»¶æ¨™é¡Œ
        use_llm (bool): æ˜¯å¦ä½¿ç”¨ LLM è™•ç†åœ–ç‰‡
        api_key (Optional[str]): OpenAI API Key
        model (str): ä½¿ç”¨çš„ OpenAI æ¨¡å‹
        
    Returns:
        Tuple[bool, str, Dict]: (æ˜¯å¦æˆåŠŸ, è¼¸å‡ºæª”æ¡ˆè·¯å¾‘, è™•ç†è³‡è¨Š)
    """
    try:
        logger.info(f"å°‡ {len(image_paths)} å¼µåœ–ç‰‡è½‰æ›ç‚º Markdown")
        
        # æª¢æŸ¥åœ–ç‰‡åˆ—è¡¨
        if not image_paths:
            logger.error("åœ–ç‰‡åˆ—è¡¨ç‚ºç©º")
            return False, "", {"error": "åœ–ç‰‡åˆ—è¡¨ç‚ºç©º"}
            
        # éæ¿¾æœ‰æ•ˆçš„åœ–ç‰‡æª”æ¡ˆ
        valid_images = []
        for img_path in image_paths:
            if os.path.exists(img_path):
                valid_images.append(img_path)
            else:
                logger.warning(f"æ‰¾ä¸åˆ°åœ–ç‰‡: {img_path}")
                
        if not valid_images:
            logger.error("æ²’æœ‰æœ‰æ•ˆçš„åœ–ç‰‡æª”æ¡ˆ")
            return False, "", {"error": "æ²’æœ‰æœ‰æ•ˆçš„åœ–ç‰‡æª”æ¡ˆ"}
        
        # ç”Ÿæˆåˆå§‹ Markdown æ–‡æœ¬
        md_content = f"# {title}\n\n"
        
        # å»ºç«‹ MarkItDown å¯¦ä¾‹
        md_kwargs = {"enable_plugins": True}
        llm_client = None
        llm_info = {}
        
        if use_llm:
            logger.info(f"å˜—è©¦å•Ÿç”¨ LLM ({model}) é€²è¡Œè™•ç†...")
            current_api_key = api_key or os.environ.get("OPENAI_API_KEY")
            if not current_api_key:
                logger.warning("æœªæä¾› OpenAI API Keyï¼Œç„¡æ³•ä½¿ç”¨ LLM è™•ç†åœ–ç‰‡ã€‚")
                llm_info["status"] = "æœªæä¾› API Key"
                use_llm = False
            else:
                try:
                    llm_client = OpenAI(api_key=current_api_key)
                    # åŸ·è¡Œä¸€å€‹ç°¡å–®çš„æ¸¬è©¦å‘¼å«ä¾†é©—è­‰é‡‘é‘°
                    llm_client.models.list() 
                    logger.info("OpenAI API Key é©—è­‰æˆåŠŸã€‚")
                    md_kwargs["llm_client"] = llm_client
                    md_kwargs["llm_model"] = model
                    llm_info["status"] = "å•Ÿç”¨æˆåŠŸ"
                    llm_info["model"] = model
                except AuthenticationError:
                    logger.error("OpenAI API Key ç„¡æ•ˆæˆ–éŒ¯èª¤ï¼Œç„¡æ³•ä½¿ç”¨ LLMã€‚")
                    llm_info["status"] = "API Key ç„¡æ•ˆ"
                    use_llm = False
                except Exception as e:
                    logger.error(f"åˆå§‹åŒ– OpenAI client æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    llm_info["status"] = f"åˆå§‹åŒ–éŒ¯èª¤: {str(e)}"
                    use_llm = False
                    
        md = MarkItDown(**md_kwargs)
        
        # è™•ç†æ¯å€‹åœ–ç‰‡
        successful_conversions = 0
        for img_path in valid_images:
            try:
                img_relpath = os.path.basename(img_path)
                logger.info(f"è™•ç†åœ–ç‰‡: {img_relpath}")
                
                # è½‰æ›åœ–ç‰‡
                result = md.convert(img_path)
                
                if result and result.text_content:
                    md_content += f"## åœ–ç‰‡ï¼š{img_relpath}\n\n"
                    md_content += result.text_content + "\n\n"
                    successful_conversions += 1
                else:
                    logger.warning(f"ç„¡æ³•è½‰æ›åœ–ç‰‡: {img_relpath}")
                    # æ·»åŠ ç°¡å–®çš„åœ–ç‰‡æ¨™è¨˜
                    md_content += f"## åœ–ç‰‡ï¼š{img_relpath}\n\n"
                    md_content += f"![{img_relpath}]({img_path})\n\n"
            except Exception as e:
                logger.warning(f"è™•ç†åœ–ç‰‡ {img_path} æ™‚å‡ºéŒ¯: {e}")
                # æ·»åŠ ç°¡å–®çš„åœ–ç‰‡æ¨™è¨˜
                md_content += f"## åœ–ç‰‡ï¼š{img_relpath}\n\n"
                md_content += f"![{img_relpath}]({img_path})\n\n"
                
        # å¯«å…¥è¼¸å‡ºæª”æ¡ˆ
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(md_content)
            logger.info(f"å·²å°‡ {successful_conversions} å¼µåœ–ç‰‡è½‰æ›ä¸¦å¯«å…¥ {output_file}")
            
            # å˜—è©¦ä½¿ç”¨ image_analyzer å¢å¼·åœ–ç‰‡æè¿°
            if use_llm and os.path.exists(output_file):
                try:
                    from image_analyzer import enhance_markdown_with_image_analysis
                    
                    # è®€å–å‰›ç”Ÿæˆçš„ Markdown æª”æ¡ˆ
                    with open(output_file, 'r', encoding='utf-8') as f:
                        original_md = f.read()
                    
                    # å¢å¼· Markdown å…§å®¹
                    enhanced_md, stats = enhance_markdown_with_image_analysis(
                        markdown_text=original_md,
                        base_dir=os.path.dirname(output_file),
                        api_key=current_api_key,
                        model=model
                    )
                    
                    # å¯«å…¥å¢å¼·å¾Œçš„å…§å®¹
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(enhanced_md)
                    
                    logger.info(f"å·²å¢å¼· {stats['images_processed']} å¼µåœ–ç‰‡çš„æè¿°")
                    
                except ImportError:
                    logger.warning("æ‰¾ä¸åˆ° image_analyzer æ¨¡çµ„ï¼Œç„¡æ³•å¢å¼·åœ–ç‰‡æè¿°")
                except Exception as e:
                    logger.warning(f"å¢å¼·åœ–ç‰‡æè¿°æ™‚å‡ºéŒ¯: {e}")
            
            result_info = {
                "success": True,
                "total_images": len(valid_images),
                "converted_images": successful_conversions,
                "output_file": output_file,
                "llm": llm_info
            }
            
            return True, output_file, result_info
            
        except Exception as e:
            logger.error(f"å¯«å…¥è¼¸å‡ºæª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False, "", {"error": f"å¯«å…¥è¼¸å‡ºæª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"}
        
    except Exception as e:
        logger.error(f"è½‰æ›åœ–ç‰‡é›†åˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        error_details = traceback.format_exc()
        logger.error(error_details)
        return False, "", {"error": str(e), "details": error_details}


def extract_slide_as_image(presentation, slide_index: int, input_path: str) -> Optional[str]:
    """
    å°‡ PowerPoint æŠ•å½±ç‰‡è½‰æ›ç‚ºåœ–ç‰‡
    
    Args:
        presentation: python-pptx Presentation ç‰©ä»¶
        slide_index: æŠ•å½±ç‰‡ç´¢å¼• (0-based)
        input_path: åŸå§‹ PPTX æª”æ¡ˆè·¯å¾‘
        
    Returns:
        Optional[str]: è‡¨æ™‚åœ–ç‰‡æª”æ¡ˆè·¯å¾‘ï¼Œå¤±æ•—æ™‚è¿”å› None
    """
    try:
        # é€™è£¡éœ€è¦ä½¿ç”¨å…¶ä»–æ–¹æ³•ä¾†å°‡æŠ•å½±ç‰‡è½‰ç‚ºåœ–ç‰‡
        # ç”±æ–¼ python-pptx ä¸ç›´æ¥æ”¯æ´è½‰åœ–ç‰‡ï¼Œæˆ‘å€‘å¯ä»¥ä½¿ç”¨å…¶ä»–æ–¹æ¡ˆ
        
        # æ–¹æ¡ˆ 1: å˜—è©¦ä½¿ç”¨ PIL å’Œ python-pptx çš„å½¢ç‹€è³‡è¨Š
        # ä½†é€™å€‹æ–¹æ³•æœ‰é™åˆ¶ï¼Œæ›´å¥½çš„æ–¹æ¡ˆæ˜¯ä½¿ç”¨å¤–éƒ¨å·¥å…·
        
        # æš«æ™‚è¿”å› Noneï¼Œè¡¨ç¤ºç„¡æ³•æå–åœ–ç‰‡
        # åœ¨å¯¦éš›ä½¿ç”¨ä¸­ï¼Œå¯ä»¥æ•´åˆ LibreOffice æˆ–å…¶ä»–å·¥å…·
        logger.warning(f"æŠ•å½±ç‰‡ {slide_index + 1} åœ–ç‰‡æå–åŠŸèƒ½å°šæœªå®Œå…¨å¯¦ç¾")
        return None
        
    except Exception as e:
        logger.error(f"æå–æŠ•å½±ç‰‡ {slide_index + 1} ç‚ºåœ–ç‰‡æ™‚å‡ºéŒ¯: {e}")
        return None


def analyze_slide_image(image_path: str, api_key: str, model: str = "gpt-4o") -> Optional[str]:
    """
    ä½¿ç”¨ OpenAI Vision API åˆ†ææŠ•å½±ç‰‡åœ–ç‰‡
    
    Args:
        image_path: åœ–ç‰‡æª”æ¡ˆè·¯å¾‘
        api_key: OpenAI API Key
        model: ä½¿ç”¨çš„æ¨¡å‹åç¨±
        
    Returns:
        Optional[str]: åˆ†æçµæœæ–‡å­—ï¼Œå¤±æ•—æ™‚è¿”å› None
    """
    try:
        client = OpenAI(api_key=api_key)
        
        # è®€å–ä¸¦ç·¨ç¢¼åœ–ç‰‡
        with open(image_path, "rb") as image_file:
            base64_image = base64.b64encode(image_file.read()).decode('utf-8')
        
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "è«‹ä»”ç´°åˆ†æé€™å¼µæŠ•å½±ç‰‡åœ–ç‰‡çš„å…§å®¹ï¼ŒåŒ…æ‹¬æ–‡å­—ã€åœ–è¡¨ã€åœ–åƒç­‰å…ƒç´ ï¼Œä¸¦ç”¨ç¹é«”ä¸­æ–‡è©³ç´°æè¿°ã€‚è«‹ç‰¹åˆ¥æ³¨æ„ï¼š1) æå–æ‰€æœ‰å¯è¦‹çš„æ–‡å­—å…§å®¹ 2) æè¿°åœ–è¡¨ã€åœ–åƒçš„é¡å‹å’Œå…§å®¹ 3) è§£é‡‹æŠ•å½±ç‰‡çš„ä¸»è¦è¨Šæ¯å’Œé‡é»"
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=1000,
            temperature=0.3
        )
        
        result = response.choices[0].message.content
        logger.info(f"æˆåŠŸåˆ†ææŠ•å½±ç‰‡åœ–ç‰‡ï¼Œçµæœé•·åº¦: {len(result) if result else 0}")
        return result
        
    except Exception as e:
        logger.error(f"ä½¿ç”¨ Vision API åˆ†ææŠ•å½±ç‰‡åœ–ç‰‡æ™‚å‡ºéŒ¯: {e}")
        return None 