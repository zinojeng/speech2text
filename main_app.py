# æ¨™æº–åº«å°å…¥
import os
import logging
import tempfile
import time
import base64

# ç¬¬ä¸‰æ–¹åº«å°å…¥
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
import google.generativeai as genai
from pydub import AudioSegment

# æœ¬åœ°æ¨¡çµ„å°å…¥
from whisper_stt import get_model_description
from transcript_refiner import refine_transcript
from markitdown_utils import (
    convert_file_to_markdown,
    extract_keywords, save_uploaded_file
)
# å°å…¥åœ–åƒåˆ†æåŠŸèƒ½
from image_analyzer import (
    analyze_image,
    enhance_slides
)

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å®šç¾©å¯ç”¨çš„ OpenAI æ¨¡å‹
AVAILABLE_MODELS = {
    "o4-mini": "o4-mini",  # æ–°æ¨¡å‹æ”¾å‰é¢ä½œç‚ºé è¨­
    "gpt-4o": "gpt-4o",
    "gpt-4o-mini": "gpt-4o-mini",
    "o3-mini": "o3-mini",
    "o1-mini": "o1-mini"
}

# æ¨¡å‹è¨­å®šå’Œåƒ¹æ ¼ï¼ˆUSD per 1M tokensï¼‰
MODEL_CONFIG = {
    "o4-mini": {
        "display_name": "o4-mini",
        "input": 0.15,          # $0.15 per 1M tokens
        "cached_input": 0.075,  # $0.075 per 1M tokens
        "output": 0.60          # $0.60 per 1M tokens
    },
    "gpt-4o": {
        "display_name": "gpt-4o",
        "input": 2.50,          # $2.50 per 1M tokens
        "cached_input": 1.25,   # $1.25 per 1M tokens
        "output": 10.00         # $10.00 per 1M tokens
    },
    "gpt-4o-mini": {
        "display_name": "gpt-4o-mini",
        "input": 0.15,          # $0.15 per 1M tokens
        "cached_input": 0.075,  # $0.075 per 1M tokens
        "output": 0.60          # $0.60 per 1M tokens
    },
    "o1-mini": {
        "display_name": "o1-mini",
        "input": 1.10,          # $1.10 per 1M tokens
        "cached_input": 0.55,   # $0.55 per 1M tokens
        "output": 4.40          # $4.40 per 1M tokens
    },
    "o3-mini": {
        "display_name": "o3-mini",
        "input": 1.10,          # $1.10 per 1M tokens
        "cached_input": 0.55,   # $0.55 per 1M tokens
        "output": 4.40          # $4.40 per 1M tokens
    },
    "gemini-2.5-pro-preview-05-06": {
        "display_name": "Gemini 2.5 Pro Experimental",
        "input": 0.00,          # åƒ¹æ ¼å¾…å®š
        "cached_input": 0.00,   # åƒ¹æ ¼å¾…å®š
        "output": 0.00          # åƒ¹æ ¼å¾…å®š
    },
    "gemini-2.5-flash-preview-04-17": {
        "display_name": "Gemini 2.5 Flash Preview",
        "input": 0.00,          # åƒ¹æ ¼å¾…å®š
        "cached_input": 0.00,   # åƒ¹æ ¼å¾…å®š
        "output": 0.00          # åƒ¹æ ¼å¾…å®š
    }
}

# åŒ¯ç‡è¨­å®š
USD_TO_NTD = 31.5

# è½‰éŒ„æœå‹™èªªæ˜
TRANSCRIPTION_SERVICE_INFO = {
    "Whisper": """
    ### Whisper æ¨¡å‹
    - é–‹æºçš„èªéŸ³è½‰æ–‡å­—æ¨¡å‹
    - æ”¯æ´å¤šç¨®èªè¨€
    - å¯é›¢ç·šä½¿ç”¨
    """,
    "ElevenLabs": """
    ### ElevenLabs æ¨¡å‹
    - å•†æ¥­ç´šèªéŸ³è½‰æ–‡å­—æœå‹™
    - æ”¯æ´ 99 ç¨®èªè¨€
    - æä¾›èªªè©±è€…è¾¨è­˜åŠŸèƒ½
    """,
    "OpenAI 2025 New": """
    ### OpenAI 2025 å…¨æ–°æ¨¡å‹
    - gpt-4o-transcribeï¼šé«˜ç²¾åº¦ã€å¤šèªè¨€æ”¯æ´
    - gpt-4o-mini-transcribeï¼šè¼•é‡å¿«é€Ÿã€æ€§åƒ¹æ¯”é«˜
    - è‡ªå‹•èªè¨€æª¢æ¸¬
    - æ›´å¥½çš„ä¸­æ–‡è½‰éŒ„æ•ˆæœ
    """
}

# å„ªåŒ–æœå‹™èªªæ˜
OPTIMIZATION_SERVICE_INFO = {
    "OpenAI": """
    ### OpenAI å„ªåŒ–æ¨¡å‹
    - å°ˆæ¥­çš„æ–‡å­—å„ªåŒ–å’Œæ ¡æ­£
    - æ”¯æ´å¤šç¨®èªè¨€
    - å¯è‡ªè¨‚å„ªåŒ–ç¨‹åº¦
    """,
    "Gemini": """
    ### Google Gemini 2.5 Pro (å¯¦é©—æ€§)
    - æœ€æ–°çš„ Google AI æ¨¡å‹
    - æ›´å¼·çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›
    - æ›´è‡ªç„¶çš„èªè¨€è™•ç†
    - æ”¯æ´å¤šèªè¨€å„ªåŒ–
    - å¯¦é©—æ€§åŠŸèƒ½ï¼ŒæŒçºŒæ”¹é€²ä¸­
    """
}

# MarkItDown æœå‹™èªªæ˜
MARKITDOWN_SERVICE_INFO = """
### MarkItDown æ–‡ä»¶è½‰æ›å·¥å…·
- å°‡å„ç¨®æ ¼å¼çš„æ–‡ä»¶è½‰æ›ç‚º Markdown
- æ”¯æ´ PDFã€DOCXã€PowerPointã€Excel ç­‰æ ¼å¼
- å¯æå–é—œéµè©
"""

# æ”¯æ´çš„æª”æ¡ˆé¡å‹
SUPPORTED_FILE_TYPES = [
    "pdf", "docx", "doc", "pptx", "ppt", 
    "xlsx", "xls", "csv", "txt", "rtf", 
    "html", "htm", "md", "markdown"
]

def encode_image_to_base64(image_path: str) -> str:
    """
    å°‡åœ–ç‰‡ç·¨ç¢¼ç‚º base64 å­—ä¸²
    
    Args:
        image_path (str): åœ–ç‰‡æª”æ¡ˆè·¯å¾‘
        
    Returns:
        str: base64 ç·¨ç¢¼çš„åœ–ç‰‡å­—ä¸²
    """
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except Exception as e:
        logger.error(f"åœ–ç‰‡ç·¨ç¢¼å¤±æ•—: {str(e)}")
        return ""

def calculate_cost(input_tokens, output_tokens, model_name, is_cached=False):
    """è¨ˆç®— API ä½¿ç”¨æˆæœ¬
    
    Args:
        input_tokens (int): è¼¸å…¥ tokens æ•¸é‡
        output_tokens (int): è¼¸å‡º tokens æ•¸é‡
        model_name (str): æ¨¡å‹åç¨±
        is_cached (bool, optional): æ˜¯å¦ä½¿ç”¨å¿«å–è¼¸å…¥åƒ¹æ ¼. é è¨­ç‚º False
    
    Returns:
        tuple: (USD æˆæœ¬, NTD æˆæœ¬, è©³ç´°è¨ˆç®—è³‡è¨Š)
    """
    if model_name not in MODEL_CONFIG:
        return 0, 0, "æœªæ”¯æ´çš„æ¨¡å‹"
        
    # å–å¾—åƒ¹æ ¼è¨­å®š
    model = MODEL_CONFIG[model_name]
    input_price = model["cached_input"] if is_cached else model["input"]
    output_price = model["output"]
    
    # è¨ˆç®— USD æˆæœ¬ (ä»¥æ¯ 1M tokens ç‚ºå–®ä½)
    input_cost = (input_tokens / 1_000_000) * input_price
    output_cost = (output_tokens / 1_000_000) * output_price
    total_cost_usd = input_cost + output_cost
    total_cost_ntd = total_cost_usd * USD_TO_NTD
    
    # æº–å‚™è©³ç´°è¨ˆç®—è³‡è¨Š
    details = f"""
    è¨ˆç®—æ˜ç´° (USD):
    - è¼¸å…¥: {input_tokens:,} tokens Ã— ${input_price}/1M = ${input_cost:.4f}
    - è¼¸å‡º: {output_tokens:,} tokens Ã— ${output_price}/1M = ${output_cost:.4f}
    - ç¸½è¨ˆ (USD): ${total_cost_usd:.4f}
    - ç¸½è¨ˆ (NTD): NT${total_cost_ntd:.2f}
    """
    return total_cost_usd, total_cost_ntd, details

def refine_transcript_gemini(text, api_key, temperature=0.5, context=""):
    """ä½¿ç”¨ Gemini æ¨¡å‹å„ªåŒ–æ–‡å­—

    Args:
        text (str): è¦å„ªåŒ–çš„æ–‡å­—
        api_key (str): Gemini API é‡‘é‘°
        temperature (float): å‰µæ„ç¨‹åº¦ (0.0-1.0)
        context (str): ä¸Šä¸‹æ–‡æç¤º

    Returns:
        dict: åŒ…å«å„ªåŒ–å¾Œçš„æ–‡å­—å’Œæ‘˜è¦
    """
    try:
        genai.configure(api_key=api_key)
        # ä½¿ç”¨ session_state ä¸­é¸æ“‡çš„æ¨¡å‹ï¼Œå¦‚æœæœªè¨­ç½®å‰‡ä½¿ç”¨é è¨­å€¼
        model_name = st.session_state.get("gemini_model", "gemini-2.5-pro-preview-05-06")
        model = genai.GenerativeModel(model_name)
        
        # æº–å‚™æç¤ºè©
        prompt = f"""
        è«‹å°‡ä»¥ä¸‹æ–‡å­—å„ªåŒ–ç‚ºä¸€ä»½çµæ§‹å®Œæ•´ã€æ ¼å¼è±å¯Œçš„æœƒè­°è¨˜éŒ„æˆ–è¬›ç¨¿è‰ç¨¿ã€‚
        ç„¡è«–è¼¸å…¥æ–‡å­—æ˜¯ç°¡é«”æˆ–ç¹é«”ä¸­æ–‡ï¼Œè«‹å‹™å¿…å°‡æ‰€æœ‰è¼¸å‡ºè½‰æ›ç‚ºç¹é«”ä¸­æ–‡ã€‚

        # ä»»å‹™è¦æ±‚
        1. **åŸºæœ¬è¦æ±‚**
           - å°‡æ‰€æœ‰æ–‡å­—è½‰æ›ç‚ºç¹é«”ä¸­æ–‡
           - ä¿æŒåŸæ„çš„æƒ…æ³ä¸‹è®“æ–‡å­—æ›´é€šé †ã€å°ˆæ¥­
           - è£½ä½œé‡é»æ‘˜è¦ï¼ˆ300å­—ä»¥å…§ï¼‰

        2. **æ ¼å¼è¦æ±‚**ï¼ˆè«‹åƒè€ƒä»¥ä¸‹ç¯„ä¾‹æ ¼å¼ï¼‰
           - ä½¿ç”¨ `---` ä½œç‚ºä¸»è¦åˆ†éš”ç·š
           - ä½¿ç”¨ `# ## ###` ç­‰æ¨™é¡Œå±¤ç´šå€åˆ†ä¸»é¡Œ
           - ä½¿ç”¨ `**ç²—é«”**` æ¨™ç¤ºï¼š
             * æ¨™é¡Œï¼ˆå¦‚ï¼š**æ¨™é¡Œï¼š**ï¼‰
             * è¬›è€…ï¼ˆå¦‚ï¼š**[è¬›è€…]:**ï¼‰
             * é—œéµè©æˆ–é‡è¦æ¦‚å¿µ
           - ä½¿ç”¨ `-` æˆ– `*` è£½ä½œé …ç›®æ¸…å–®ï¼Œæ”¯æ´å¤šå±¤ç¸®æ’
           - ä½¿ç”¨ `>` è£½ä½œå¼•ç”¨å€å¡Šï¼ˆé©ç”¨æ–¼é‡è¦å¼•è¿°ï¼‰
           - é©ç•¶ä½¿ç”¨ `*æ–œé«”*` å¼·èª¿æ¬¡è¦é‡é»

        # ä¸Šä¸‹æ–‡è³‡è¨Š
        {context if context else "ç„¡ç‰¹å®šä¸Šä¸‹æ–‡"}

        # åŸå§‹æ–‡å­—
        {text}

        # è«‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›æ‡‰ï¼ˆå¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼‰

        [å„ªåŒ–å¾Œæ–‡å­—]
        ---

        **(æœƒè­°è¨˜éŒ„/è¬›ç¨¿è‰ç¨¿ - è©³ç´°ç‰ˆ)**

        **æ¨™é¡Œï¼š** [ä¸»è¦æ¨™é¡Œ]

        **æ—¥æœŸï¼š** [æ—¥æœŸï¼Œè‹¥æœ‰]
        **åƒèˆ‡è€…ï¼š** [ç›¸é—œäººå“¡ï¼Œè‹¥æœ‰]

        ## 1. èƒŒæ™¯èªªæ˜
        **ä¸»è¦è­°é¡Œï¼š**
        - é‡é»ä¸€
          - ç´°ç¯€èªªæ˜
          - è£œå……è³‡è¨Š
        - é‡é»äºŒ
          - ç›¸é—œæ•¸æ“š
          - å…·é«”æ¡ˆä¾‹

        **[ç™¼è¨€è€…å§“å/è§’è‰²]:** ã€Œé‡è¦ç™¼è¨€å…§å®¹...ã€

        ## 2. è¨è«–å…§å®¹
        ### 2.1 è­°é¡Œæ¢è¨
        **ç¾æ³åˆ†æï¼š**
        - **ç›®å‰é€²åº¦ï¼š** èªªæ˜...
        - **é‡åˆ°æŒ‘æˆ°ï¼š**
          - æŒ‘æˆ°ä¸€
          - æŒ‘æˆ°äºŒ

        **è§£æ±ºæ–¹æ¡ˆï¼š**
        1. æ–¹æ¡ˆä¸€
           - å„ªé»ï¼š...
           - è€ƒé‡ï¼š...
        2. æ–¹æ¡ˆäºŒ
           - å»ºè­°åšæ³•ï¼š...
           - æ‰€éœ€è³‡æºï¼š...

        ### 2.2 æ±ºè­°äº‹é …
        **çµè«–ï¼š**
        - é‡è¦æ±ºå®šä¸€
        - é‡è¦æ±ºå®šäºŒ

        ## 3. å¾ŒçºŒè¦åŠƒ
        **æ™‚ç¨‹å®‰æ’ï¼š**
        - çŸ­æœŸç›®æ¨™ï¼ˆ1å€‹æœˆå…§ï¼‰
        - ä¸­æœŸç›®æ¨™ï¼ˆ3å€‹æœˆå…§ï¼‰
        - é•·æœŸç›®æ¨™ï¼ˆ6å€‹æœˆä»¥ä¸Šï¼‰

        **å¾…è¾¦äº‹é …ï¼š**
        1. å„ªå…ˆè™•ç†ï¼š...
        2. å¾ŒçºŒè¿½è¹¤ï¼š...

        ---

        [é‡é»æ‘˜è¦]
        ## æœƒè­°é‡é»æ‘˜è¦

        **æ ¸å¿ƒè­°é¡Œï¼š**
        1. ä¸»è¦è¨è«–é‡é»
           - é—œéµç™¼ç¾
           - é‡è¦æ±ºè­°
        
        **åŸ·è¡Œæ–¹å‘ï¼š**
        - è¿‘æœŸè¡Œå‹•é …ç›®
          - è² è²¬å–®ä½
          - æ™‚ç¨‹è¦åŠƒ
        
        **æ³¨æ„äº‹é …ï¼š**
        - éœ€è¦ç‰¹åˆ¥é—œæ³¨çš„è­°é¡Œ
        - æ½›åœ¨é¢¨éšªèˆ‡å› æ‡‰æªæ–½
        """
        
        response = model.generate_content(
            prompt,
            generation_config={
                'temperature': temperature
            }
        )
        
        # è§£æå›æ‡‰
        response_text = response.text
        
        # ä½¿ç”¨æ–°çš„åˆ†éš”æ–¹å¼è§£æå›æ‡‰
        if "[å„ªåŒ–å¾Œæ–‡å­—]" in response_text and "[é‡é»æ‘˜è¦]" in response_text:
            parts = response_text.split("[é‡é»æ‘˜è¦]")
            corrected = parts[0].split("[å„ªåŒ–å¾Œæ–‡å­—]")[1].strip()
            summary = parts[1].strip()
        else:
            # å¦‚æœæ‰¾ä¸åˆ°æ¨™è¨˜ï¼Œå˜—è©¦ä½¿ç”¨èˆŠçš„åˆ†éš”æ–¹å¼
            parts = response_text.split("é‡é»æ‘˜è¦ï¼š")
            if len(parts) >= 2:
                corrected = parts[0].strip()
                summary = parts[1].strip()
            else:
                corrected = response_text
                summary = "ç„¡æ³•ç”Ÿæˆæ‘˜è¦"
        
        return {
            "corrected": corrected,
            "summary": summary,
            "usage": {
                "total_input_tokens": 0,  # Gemini æš«æ™‚ä¸è¨ˆç®— tokens
                "total_output_tokens": 0
            }
        }
    except Exception as e:
        logger.error(f"Gemini API éŒ¯èª¤ï¼š{str(e)}")
        return None

def display_cost_info(
    input_tokens,
    output_tokens,
    model_name,
    is_cached=False
):
    """åœ¨ Streamlit ä»‹é¢ä¸­é¡¯ç¤ºæˆæœ¬è³‡è¨Š"""
    cost_usd, cost_ntd, details = calculate_cost(
        input_tokens,
        output_tokens,
        model_name,
        is_cached
    )
    
    with st.sidebar.expander("ğŸ’° æˆæœ¬è¨ˆç®—", expanded=True):
        st.write("### Token ä½¿ç”¨é‡")
        st.write(f"- è¼¸å…¥: {input_tokens:,} tokens")
        st.write(f"- è¼¸å‡º: {output_tokens:,} tokens")
        st.write(f"- ç¸½è¨ˆ: {input_tokens + output_tokens:,} tokens")
        
        if (input_tokens + output_tokens) == 0:
            st.warning("ç›®å‰ token ä½¿ç”¨é‡ç‚º 0ï¼Œè«‹ç¢ºèªæ˜¯å¦å·²æ­£ç¢ºè¨ˆç®— token æ•¸é‡ï¼")
        
        st.write("### è²»ç”¨æ˜ç´°")
        st.text(details)
        
        if is_cached:
            st.info("âœ¨ ä½¿ç”¨å¿«å–åƒ¹æ ¼è¨ˆç®—")

def process_markdown_extraction(text, api_key, model, keyword_count):
    """
    è™•ç† Markdown æ–‡æœ¬æå–é—œéµè©
    
    Args:
        text (str): Markdown æ–‡æœ¬
        api_key (str): OpenAI API Key
        model (str): æ¨¡å‹åç¨±
        keyword_count (int): è¦æå–çš„é—œéµè©æ•¸é‡
        
    Returns:
        List[str]: é—œéµè©åˆ—è¡¨
    """
    try:
        with st.spinner("æ­£åœ¨æå–é—œéµè©..."):
            keywords = extract_keywords(
                markdown_text=text,
                api_key=api_key,
                model=model,
                count=keyword_count
            )
            return keywords
    except Exception as e:
        st.error(f"æå–é—œéµè©å¤±æ•—: {str(e)}")
        logger.error(f"æå–é—œéµè©å¤±æ•—: {str(e)}")
        return []

def render_markitdown_tab():
    """æ¸²æŸ“ MarkItDown æ¨™ç±¤é """
    st.header("Step 1: æ–‡ä»¶èˆ‡åœ–åƒè™•ç†")
    
    # MarkItDown æœå‹™èªªæ˜
    st.markdown(MARKITDOWN_SERVICE_INFO)
    
    # åˆå§‹åŒ– session state
    if "markdown_text" not in st.session_state:
        st.session_state.markdown_text = None
    if "markdown_keywords" not in st.session_state:
        st.session_state.markdown_keywords = None
    if "analyzed_images" not in st.session_state:
        st.session_state.analyzed_images = {}
    if "enhanced_slides" not in st.session_state:
        st.session_state.enhanced_slides = None
    if "editing_keywords" not in st.session_state:
        st.session_state.editing_keywords = False
    if "transcription_prompt" not in st.session_state:
        st.session_state.transcription_prompt = ""

    # å‰µå»ºå…©å€‹æ¨™ç±¤é ï¼šå…§å®¹è¼¸å…¥å’Œå¢å¼·èˆ‡åˆ†æ
    tab1, tab2 = st.tabs(["ğŸ“„ å…§å®¹è¼¸å…¥", "âœ¨ å¢å¼·èˆ‡åˆ†æ"])
    
    # å…§å®¹è¼¸å…¥æ¨™ç±¤é 
    with tab1:
        st.subheader("æ–‡ä»¶åŠåœ–ç‰‡ä¸Šå‚³æˆ–ç›´æ¥è¼¸å…¥")
        
        # é¸æ“‡è¼¸å…¥é¡å‹
        input_type = st.radio(
            "é¸æ“‡è¼¸å…¥æ–¹å¼",
            ["æª”æ¡ˆä¸Šå‚³", "ç›´æ¥è¼¸å…¥"],
            horizontal=True
        )
        
        if input_type == "æª”æ¡ˆä¸Šå‚³":
            # æ•´åˆæ–‡ä»¶å’Œåœ–ç‰‡ä¸Šå‚³ç‚ºå–®ä¸€ä¸Šå‚³å€åŸŸ
            st.markdown("""
            æ”¯æŒä»¥ä¸‹æª”æ¡ˆé¡å‹ï¼š
            - æ–‡ä»¶ï¼šPDF, DOCX, DOC, PPTX, PPT, XLSX, XLS, CSV, TXT, RTF, HTML, 
              HTM, MD, MARKDOWN
            - åœ–ç‰‡ï¼šJPG, JPEG, PNG
            
            æª”æ¡ˆå¤§å°é™åˆ¶ï¼šæ¯å€‹æª”æ¡ˆ 200MB
            """)
            
            # åˆä½µæ‰€æœ‰æ”¯æŒçš„æª”æ¡ˆé¡å‹
            all_supported_files = SUPPORTED_FILE_TYPES + ["jpg", "jpeg", "png"]
            
            # å–®ä¸€ä¸Šå‚³ç•Œé¢
            uploaded_files = st.file_uploader(
                "æ‹–æ”¾æª”æ¡ˆåˆ°æ­¤è™•ä¸Šå‚³",
                type=all_supported_files,
                accept_multiple_files=True,
                help="æ”¯æŒæ–‡ä»¶å’Œåœ–ç‰‡åŒæ™‚ä¸Šå‚³ï¼Œç³»çµ±æœƒè‡ªå‹•è­˜åˆ¥æª”æ¡ˆé¡å‹"
            )
            
            # æª¢æŸ¥æ˜¯å¦æœ‰ OpenAI API é‡‘é‘°
            openai_api_key = st.session_state.get("openai_api_key", "")
            
            # æ·»åŠ  Vision API é¸é …
            use_vision_api = st.checkbox(
                "ğŸ” å•Ÿç”¨ Vision API åˆ†æ (é©ç”¨æ–¼ PPTX åœ–ç‰‡æŠ•å½±ç‰‡)",
                value=True,
                help="ç•¶ PPTX æŠ•å½±ç‰‡æ²’æœ‰æ–‡å­—æ™‚ï¼Œä½¿ç”¨ OpenAI Vision API åˆ†æåœ–ç‰‡å…§å®¹ã€‚éœ€è¦ OpenAI API é‡‘é‘°ã€‚"
            )
            
            # å¦‚æœå•Ÿç”¨äº† Vision API ä½†æ²’æœ‰ API é‡‘é‘°ï¼Œé¡¯ç¤ºè­¦å‘Š
            if use_vision_api and not openai_api_key:
                st.warning("âš ï¸ å·²å•Ÿç”¨ Vision APIï¼Œä½†æœªæä¾› OpenAI API é‡‘é‘°ã€‚è«‹åœ¨å´é‚Šæ¬„å¡«å…¥ API é‡‘é‘°ä»¥ä½¿ç”¨æ­¤åŠŸèƒ½ã€‚")
            
            # è™•ç†èªªæ˜
            if uploaded_files:
                # åˆ†é¡ä¸Šå‚³çš„æª”æ¡ˆ
                doc_files = []
                image_files = []
                
                for file in uploaded_files:
                    file_ext = file.name.split('.')[-1].lower()
                    if file_ext in ["jpg", "jpeg", "png"]:
                        image_files.append(file)
                    else:
                        doc_files.append(file)
                
                # é¡¯ç¤ºæª”æ¡ˆè³‡è¨Š
                if doc_files and image_files:
                    st.info(
                        f"å·²ä¸Šå‚³ {len(doc_files)} å€‹æ–‡ä»¶å’Œ {len(image_files)} å¼µåœ–ç‰‡"
                    )
                    process_btn_label = "ğŸ”„ è™•ç†æ–‡ä»¶å’Œåˆ†æåœ–ç‰‡"
                elif doc_files:
                    st.info(f"å·²ä¸Šå‚³ {len(doc_files)} å€‹æ–‡ä»¶")
                    process_btn_label = "ğŸ”„ è½‰æ›æ–‡ä»¶ç‚º Markdown"
                elif image_files:
                    st.info(f"å·²ä¸Šå‚³ {len(image_files)} å¼µåœ–ç‰‡")
                    process_btn_label = "ğŸ”„ åˆ†æåœ–ç‰‡"
                else:
                    st.warning("è«‹ä¸Šå‚³æ–‡ä»¶æˆ–åœ–ç‰‡é€²è¡Œè™•ç†")
                    return
                
                # æ•´åˆè™•ç†æŒ‰éˆ•
                if not openai_api_key:
                    st.warning("è«‹åœ¨å´é‚Šæ¬„æä¾› OpenAI API é‡‘é‘°ä»¥é€²è¡Œåˆ†æ")
                else:
                    process_btn = st.button(
                        process_btn_label,
                        use_container_width=True
                    )
                    
                    if process_btn:
                        # è™•ç†æµç¨‹
                        with st.spinner("æ­£åœ¨è™•ç†..."):
                            temp_markdown = ""
                            
                            # è™•ç†æ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
                            if doc_files:
                                # è™•ç†ç¬¬ä¸€å€‹æ–‡ä»¶ï¼ˆç›®å‰åªæ”¯æ´è™•ç†ä¸€å€‹æ–‡ä»¶ï¼‰
                                uploaded_file = doc_files[0]
                                success, temp_path = save_uploaded_file(
                                    uploaded_file
                                )
                                
                                if success:
                                    # è½‰æ›æª”æ¡ˆ
                                    st.info("æ­£åœ¨è½‰æ›æ–‡ä»¶...")
                                    success, md_text, info = (
                                        convert_file_to_markdown(
                                            input_path=temp_path,
                                            use_llm=use_vision_api,
                                            api_key=openai_api_key,
                                            model="gpt-4o"  # Vision API éœ€è¦ gpt-4o æ¨¡å‹
                                        )
                                    )
                                    
                                    # å¦‚æœè½‰æ›å¤±æ•—ä¸”æ˜¯ magika ç›¸é—œéŒ¯èª¤ï¼Œæä¾›ä¿®å¾©å»ºè­°
                                    if not success and "magika" in str(info.get("error", "")).lower():
                                        st.error("æª”æ¡ˆè½‰æ›å¤±æ•—ï¼šmagika å¥—ä»¶é…ç½®å•é¡Œ")
                                        st.markdown("""
                                        **è§£æ±ºæ–¹æ¡ˆï¼š**
                                        1. åœ¨çµ‚ç«¯æ©ŸåŸ·è¡Œä»¥ä¸‹å‘½ä»¤ä¿®å¾© magika å¥—ä»¶ï¼š
                                        ```bash
                                        python fix_magika.py
                                        ```
                                        
                                        2. æˆ–è€…æ‰‹å‹•åŸ·è¡Œï¼š
                                        ```bash
                                        pip uninstall magika -y
                                        pip install magika --no-cache-dir
                                        ```
                                        
                                        3. é‡æ–°å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼
                                        """)
                                        # è·³éå¾ŒçºŒè™•ç†ï¼Œç›´æ¥è¿”å›
                                        return
                                    
                                    # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                                    try:
                                        os.remove(temp_path)
                                    except Exception as e:
                                        logger.error(
                                            f"æ¸…ç†è‡¨æ™‚æª”æ¡ˆå¤±æ•—: {str(e)}"
                                        )
                                        pass
                                    
                                    if success:
                                        temp_markdown = md_text
                                        st.success("æ–‡ä»¶è½‰æ›æˆåŠŸï¼")
                                    else:
                                        # é¡¯ç¤ºéŒ¯èª¤è³‡è¨Š
                                        st.error(
                                            f"è½‰æ›å¤±æ•—: {info.get('error', 'æœªçŸ¥éŒ¯èª¤')}"
                                        )
                                else:
                                    st.error(
                                        f"è™•ç†ä¸Šå‚³æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {temp_path}"
                                    )
                            
                            # è™•ç†åœ–ç‰‡ï¼ˆå¦‚æœæœ‰ï¼‰
                            if image_files:
                                # å¦‚æœæœ‰æ–‡ä»¶è½‰æ›å…§å®¹ï¼Œæ·»åŠ åˆ†éš”ç·šå’Œåœ–ç‰‡åˆ†ææ¨™é¡Œ
                                if temp_markdown:
                                    temp_markdown += "\n\n## åœ–ç‰‡åˆ†æ\n\n"
                                else:
                                    temp_markdown = "# åœ–ç‰‡åˆ†æçµæœ\n\n"
                                
                                # ä¿å­˜å’Œåˆ†æåœ–ç‰‡
                                analyzed_count = 0
                                progress_bar = st.progress(0)
                                total_images = len(image_files)
                                
                                for i, img_file in enumerate(image_files):
                                    # ä¿å­˜ä¸Šå‚³çš„æª”æ¡ˆ
                                    success, temp_path = save_uploaded_file(
                                        img_file
                                    )
                                    
                                    if success:
                                        # åˆ†æåœ–ç‰‡
                                        with st.spinner(
                                            f"åˆ†æåœ–ç‰‡ {i+1}/{total_images}..."
                                        ):
                                            result = analyze_image(
                                                temp_path, 
                                                openai_api_key, 
                                                "o4-mini"  # ä½¿ç”¨o4-miniæ¨¡å‹
                                            )
                                        
                                        if result["success"]:
                                            # å„²å­˜åˆ†æçµæœ
                                            img_analysis = {
                                                "path": temp_path,
                                                "description": (
                                                    result["description"]
                                                ),
                                                "tokens": result["tokens"]
                                            }
                                            st.session_state.analyzed_images[
                                                img_file.name
                                            ] = img_analysis
                                            
                                            # é¡¯ç¤ºåœ–ç‰‡å’Œåˆ†æçµæœ
                                            st.image(
                                                temp_path, 
                                                caption=img_file.name
                                            )
                                            st.markdown("### åˆ†æçµæœ")
                                            st.markdown(result["description"])
                                            st.markdown("---")
                                            
                                            # æ·»åŠ åˆ°è‡¨æ™‚ Markdown
                                            md_title = f"### {img_file.name}\n\n"
                                            temp_markdown += md_title
                                            temp_markdown += (
                                                f"![åœ–ç‰‡]({temp_path})\n\n"
                                            )
                                            temp_markdown += (
                                                f"{result['description']}\n\n"
                                                f"---\n\n"
                                            )
                                            
                                            # å¢åŠ è™•ç†åœ–ç‰‡è¨ˆæ•¸
                                            analyzed_count += 1
                                            
                                            # æ›´æ–°é€²åº¦æ¢
                                            if progress_bar is not None:
                                                progress_percentage = (
                                                    analyzed_count / 
                                                    total_images
                                                )
                                                progress_bar.progress(
                                                    progress_percentage
                                                )
                                        else:
                                            error_msg = result.get(
                                                'error', 'æœªçŸ¥éŒ¯èª¤'
                                            )
                                            st.error(
                                                f"åˆ†æå¤±æ•—: {error_msg}"
                                            )
                                    else:
                                        st.error(
                                            f"è™•ç†ä¸Šå‚³æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {temp_path}"
                                        )
                                
                                # é¡¯ç¤ºè™•ç†å®Œæˆè¨Šæ¯
                                if analyzed_count > 0:
                                    msg = f"å·²å®Œæˆ {analyzed_count} å¼µåœ–ç‰‡çš„åˆ†æ"
                                    st.success(msg)
                            
                            # å°‡åˆ†æçµæœå­˜å„²åˆ° markdown_text ä¸­
                            if temp_markdown:
                                st.session_state.markdown_text = temp_markdown
                                st.success("æ‰€æœ‰å…§å®¹è™•ç†å®Œæˆï¼Œå¯ä»¥é€²è¡Œå¾ŒçºŒåˆ†æ")
                                st.rerun()
        
        else:  # ç›´æ¥è¼¸å…¥
            # æ–‡å­—è¼¸å…¥å€åŸŸ
            user_text = st.text_area(
                "ç›´æ¥è¼¸å…¥æ–‡å­—",
                placeholder="åœ¨æ­¤è¼¸å…¥æ‚¨çš„æ–‡å­—å…§å®¹...",
                help="ç›´æ¥è¼¸å…¥è¦è™•ç†çš„æ–‡å­—å…§å®¹",
                height=300
            )
            
            # æ–°å¢ï¼šè½‰éŒ„æç¤ºè¨­å®š
            st.markdown("### è½‰éŒ„æç¤ºè¨­å®š")
            st.markdown("""
            æä¾›æç¤ºå¯ä»¥å¹«åŠ©æ¨¡å‹æ›´æº–ç¢ºåœ°è­˜åˆ¥ç‰¹å®šè¡“èªã€å°ˆæœ‰åè©æˆ–é ˜åŸŸç‰¹å®šè©å½™ã€‚
            """)
            
            transcription_prompt = st.text_area(
                "è½‰éŒ„æç¤º (å¯é¸)",
                value=st.session_state.get("transcription_prompt", ""),
                placeholder="ä¾‹å¦‚ï¼šé€™æ˜¯ä¸€æ®µé†«å­¸æ¼”è¬›ï¼Œå¯èƒ½åŒ…å«ä»¥ä¸‹å°ˆæ¥­è¡“èª: é«˜è¡€å£“ã€ç³–å°¿ç—…ã€å¿ƒè‚Œæ¢—å¡...",
                help="æä¾›ä¸Šä¸‹æ–‡æˆ–é ˜åŸŸç‰¹å®šçš„è©å½™ï¼Œä»¥å¢å¼·è½‰éŒ„æº–ç¢ºæ€§"
            )
            
            # å„²å­˜åˆ° session state
            st.session_state["transcription_prompt"] = transcription_prompt
            
            if user_text:
                # è™•ç†æŒ‰éˆ•
                process_text_btn = st.button(
                    "âœ… è™•ç†æ–‡å­—å…§å®¹",
                    use_container_width=True
                )
                
                if process_text_btn:
                    # å„²å­˜ç”¨æˆ¶è¼¸å…¥çš„æ–‡å­—
                    st.session_state.markdown_text = user_text
                    st.success(
                        f"æ–‡å­—å…§å®¹å·²è™•ç†ï¼é•·åº¦: {len(user_text)} å­—å…ƒ"
                    )
                    st.rerun()
    
    # å¢å¼·èˆ‡åˆ†ææ¨™ç±¤é 
    with tab2:
        st.subheader("æ–‡æœ¬å¢å¼·èˆ‡åˆ†æ")
        
        # æ˜¯å¦æœ‰å…§å®¹å¯ä»¥é€²è¡Œå¢å¼·èˆ‡åˆ†æ
        if not st.session_state.markdown_text:
            st.info("è«‹å…ˆåœ¨ã€Œå…§å®¹è¼¸å…¥ã€æ¨™ç±¤é ä¸Šå‚³æ–‡ä»¶ã€åœ–ç‰‡æˆ–è¼¸å…¥æ–‡å­—")
            return
        
        # é¡¯ç¤º Markdown æ–‡å­—
        st.text_area(
            "å…§å®¹é è¦½",
            st.session_state.markdown_text,
            height=250
        )
        
        # å¢å¼·é¸é …
        st.markdown("### é¸æ“‡å¢å¼·æ“ä½œ")
        
        enhancement_type = st.radio(
            "é¸æ“‡å¢å¼·é¡å‹",
            ["æå–é—œéµè©", "å¹»ç‡ˆç‰‡å¢å¼·", "å‚³é€è‡³å„ªåŒ–åŠŸèƒ½"],
            horizontal=True
        )
        
        # æª¢æŸ¥ API é‡‘é‘°æ˜¯å¦å­˜åœ¨
        openai_api_key = st.session_state.get("openai_api_key", "")
        if not openai_api_key and enhancement_type in ["æå–é—œéµè©", "å¹»ç‡ˆç‰‡å¢å¼·"]:
            st.warning("è«‹åœ¨å´é‚Šæ¬„æä¾› OpenAI API é‡‘é‘°ä»¥é€²è¡Œå¢å¼·æ“ä½œ")
        
        # æ ¹æ“šå¢å¼·é¡å‹é¡¯ç¤ºä¸åŒçš„é¸é …
        if enhancement_type == "æå–é—œéµè©" and openai_api_key:
            col1, col2 = st.columns(2)
            
            with col1:
                model_for_keywords = st.selectbox(
                    "é¸æ“‡æ¨¡å‹",
                    ["gpt-4o", "gpt-4o-mini"],
                    index=1,
                    help="é¸æ“‡ç”¨æ–¼æå–é—œéµè©çš„æ¨¡å‹"
                )
            
            with col2:
                keyword_count = st.number_input(
                    "é—œéµè©æ•¸é‡",
                    min_value=5,
                    max_value=50,
                    value=10,
                    help="è¦æå–çš„é—œéµè©æ•¸é‡"
                )
            
            # æå–é—œéµè©æŒ‰éˆ•
            if st.button("ğŸ” æå–é—œéµè©", use_container_width=True):
                # æå–é—œéµè©
                keywords = process_markdown_extraction(
                    st.session_state.markdown_text,
                    openai_api_key,
                    model_for_keywords,
                    keyword_count
                )
                
                if keywords:
                    st.session_state.markdown_keywords = keywords
                    st.success(f"æˆåŠŸæå– {len(keywords)} å€‹é—œéµè©")
                    st.rerun()
            
            # é¡¯ç¤ºå·²æå–çš„é—œéµè©
            if st.session_state.markdown_keywords:
                # é¡¯ç¤ºé—œéµè©
                st.write("### æå–çš„é—œéµè©")
                for i, kw in enumerate(st.session_state.markdown_keywords):
                    st.write(f"{i+1}. {kw}")
                
                # è¤‡è£½é—œéµè©æŒ‰éˆ•
                keywords_text = "\n".join(st.session_state.markdown_keywords)
                st.download_button(
                    label="ğŸ“‹ ä¸‹è¼‰é—œéµè©åˆ—è¡¨",
                    data=keywords_text,
                    file_name="keywords.txt",
                    mime="text/plain",
                    help="ä¸‹è¼‰æå–çš„é—œéµè©åˆ—è¡¨",
                    use_container_width=True
                )
                
                # æ·»åŠ ç·¨è¼¯é—œéµè©çš„åŠŸèƒ½
                if st.button("âœï¸ ç·¨è¼¯é—œéµè©", use_container_width=True):
                    # å°‡é—œéµè©åˆ—è¡¨é¡¯ç¤ºåœ¨æ–‡æœ¬å€åŸŸä¸­ä¾›ç·¨è¼¯
                    st.session_state.editing_keywords = True
                    st.rerun()
                
                # ç•¶è™•æ–¼ç·¨è¼¯æ¨¡å¼æ™‚é¡¯ç¤ºç·¨è¼¯ç•Œé¢
                if st.session_state.get("editing_keywords", False):
                    edit_keywords = st.text_area(
                        "ç·¨è¼¯é—œéµè©ï¼ˆæ¯è¡Œä¸€å€‹ï¼‰",
                        value="\n".join(st.session_state.markdown_keywords),
                        height=200
                    )
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        if st.button("âœ… ç¢ºèªä¿®æ”¹", use_container_width=True):
                            # å°‡ç·¨è¼¯å¾Œçš„æ–‡æœ¬è½‰æ›ç‚ºåˆ—è¡¨
                            edited_keywords = [
                                kw.strip() 
                                for kw in edit_keywords.split("\n") 
                                if kw.strip()
                            ]
                            if edited_keywords:
                                kw_len = len(edited_keywords)
                                update_msg = (
                                    f"å·²æ›´æ–°é—œéµè©åˆ—è¡¨ï¼Œå…± {kw_len} å€‹é—œéµè©"
                                )
                                st.session_state.markdown_keywords = (
                                    edited_keywords
                                )
                                st.session_state.editing_keywords = False
                                st.success(update_msg)
                    
                    with col2:
                        if st.button("âŒ å–æ¶ˆç·¨è¼¯", use_container_width=True):
                            st.session_state.editing_keywords = False
                            st.rerun()
        
        elif enhancement_type == "å¹»ç‡ˆç‰‡å¢å¼·" and openai_api_key:
            # å¹»ç‡ˆç‰‡å¢å¼·èªªæ˜
            st.markdown("""
            ### å¹»ç‡ˆç‰‡å¢å¼·åŠŸèƒ½
            
            æ­¤åŠŸèƒ½æœƒè‡ªå‹•è­˜åˆ¥ Markdown ä¸­çš„åœ–ç‰‡ï¼Œä½¿ç”¨ AI ç‚ºåœ–ç‰‡æ·»åŠ è©³ç´°çš„æè¿°ï¼Œ
            ä¸¦ä»¥æŠ˜ç–Šå¼æè¿°çš„æ–¹å¼æ·»åŠ åˆ°å¹»ç‡ˆç‰‡ä¸­ã€‚é©åˆç”¨æ–¼å¢å¼·æ¼”ç¤ºæ–‡ç¨¿çš„è³‡è¨Šé‡ã€‚
            
            **å¹»ç‡ˆç‰‡æ ¼å¼ç¯„ä¾‹**ï¼š
            ```markdown
            <!-- Slide number: 1 -->
            # æ¨™é¡Œå¹»ç‡ˆç‰‡
            
            ## å‰¯æ¨™é¡Œ
            
            * é …ç›®ä¸€
            * é …ç›®äºŒ
            
            ![åœ–ç‰‡èªªæ˜](images/example.jpg)
            ```
            
            > **æ³¨æ„**ï¼šå»ºè­°ä½¿ç”¨ `<!-- Slide number: X -->` ä½œç‚ºå¹»ç‡ˆç‰‡åˆ†éš”ç¬¦ï¼Œ
            > é€™å°‡å¹«åŠ©ç³»çµ±æ­£ç¢ºè­˜åˆ¥æ¯å€‹å¹»ç‡ˆç‰‡å€å¡Šã€‚
            """)
            
            # æ¨¡å‹é¸æ“‡
            slide_model = st.selectbox(
                "é¸æ“‡æ¨¡å‹",
                ["gpt-4o", "gpt-4o-mini"],
                index=1,
                help="é¸æ“‡ç”¨æ–¼å¹»ç‡ˆç‰‡å¢å¼·çš„æ¨¡å‹"
            )
            
            # å¢å¼·æŒ‰éˆ•
            if st.button("âœ¨ å¢å¼·å¹»ç‡ˆç‰‡", use_container_width=True):
                with st.spinner("æ­£åœ¨å¢å¼·å¹»ç‡ˆç‰‡å…§å®¹..."):
                    # å¢å¼·å¹»ç‡ˆç‰‡
                    result = enhance_slides(
                        st.session_state.markdown_text, 
                        openai_api_key, 
                        slide_model
                    )
                    
                    # å°‡çµæœå„²å­˜åˆ° session state
                    st.session_state.enhanced_slides = result["enhanced_text"]
                    
                    # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
                    st.markdown("### è™•ç†çµ±è¨ˆ")
                    st.write(f"è™•ç†å¹»ç‡ˆç‰‡æ•¸é‡: {result['stats']['slides_processed']}")
                    st.write(f"è™•ç†åœ–ç‰‡æ•¸é‡: {result['stats']['images_processed']}")
                    st.write(f"æˆåŠŸåˆ†æåœ–ç‰‡: {result['stats']['images_analyzed']}")
                    st.write(f"åˆ†æå¤±æ•—åœ–ç‰‡: {result['stats']['images_failed']}")
                    st.write(f"ä½¿ç”¨ Tokens: {result['stats']['total_tokens']}")
                    
                    # é¡¯ç¤ºå¢å¼·å¾Œçš„å…§å®¹
                    st.markdown("### å¢å¼·å¾Œçš„å…§å®¹")
                    st.text_area(
                        "å¢å¼·å¾Œçš„å¹»ç‡ˆç‰‡å…§å®¹",
                        result["enhanced_text"],
                        height=400
                    )
                    
                    # ä¸‹è¼‰æŒ‰éˆ•
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰å¢å¼·å¾Œçš„å¹»ç‡ˆç‰‡",
                        data=result["enhanced_text"],
                        file_name="enhanced_slides.md",
                        mime="text/markdown",
                        help="ä¸‹è¼‰å¢å¼·å¾Œçš„å¹»ç‡ˆç‰‡ Markdown æª”æ¡ˆ",
                        use_container_width=True
                    )
            
            # é¡¯ç¤ºå·²å¢å¼·çš„å¹»ç‡ˆç‰‡
            if st.session_state.enhanced_slides and not st.button:
                st.markdown("### å·²å¢å¼·çš„å¹»ç‡ˆç‰‡å…§å®¹")
                st.text_area(
                    "å¢å¼·å¾Œçš„å¹»ç‡ˆç‰‡å…§å®¹",
                    st.session_state.enhanced_slides,
                    height=400
                )
                
                # ä¸‹è¼‰æŒ‰éˆ•
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰å¢å¼·å¾Œçš„å¹»ç‡ˆç‰‡",
                    data=st.session_state.enhanced_slides,
                    file_name="enhanced_slides.md",
                    mime="text/markdown",
                    help="ä¸‹è¼‰å¢å¼·å¾Œçš„å¹»ç‡ˆç‰‡ Markdown æª”æ¡ˆ",
                    use_container_width=True
                )
        
        elif enhancement_type == "å‚³é€è‡³å„ªåŒ–åŠŸèƒ½":
            # å‚³é€è‡³å„ªåŒ–åŠŸèƒ½
            if st.button(
                "ğŸ“¤ å‚³é€è‡³æ–‡å­—å„ªåŒ–åŠŸèƒ½ (Step 3)",
                use_container_width=True
            ):
                st.session_state.transcribed_text = st.session_state.markdown_text
                st.success("å…§å®¹å·²å‚³é€è‡³æ–‡å­—å„ªåŒ–åŠŸèƒ½ (Step 3)ï¼")
                st.rerun()
        
        # ä¸‹è¼‰åŸå§‹ Markdown æª”æ¡ˆ
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Markdown æª”æ¡ˆ",
            data=st.session_state.markdown_text,
            file_name="content.md",
            mime="text/markdown",
            help="ä¸‹è¼‰ç•¶å‰å…§å®¹çš„ Markdown æª”æ¡ˆ",
            use_container_width=True
        )

def main():
    """ä¸»ç¨‹å¼å‡½æ•¸"""
    st.title("éŸ³è¨Šè½‰æ–‡å­—èˆ‡æ–‡ä»¶è™•ç†ç³»çµ±")
    
    # åˆå§‹åŒ– session state
    if "transcribed_text" not in st.session_state:
        st.session_state.transcribed_text = None
    if "input_tokens" not in st.session_state:
        st.session_state.input_tokens = 0
    if "output_tokens" not in st.session_state:
        st.session_state.output_tokens = 0
    if "total_tokens" not in st.session_state:
        st.session_state.total_tokens = 0
    if "optimized_text" not in st.session_state:
        st.session_state.optimized_text = None
    if "summary_text" not in st.session_state:
        st.session_state.summary_text = None
    if "markdown_text" not in st.session_state:
        st.session_state.markdown_text = None
    if "markdown_keywords" not in st.session_state:
        st.session_state.markdown_keywords = None
    if "transcription_prompt" not in st.session_state:
        st.session_state.transcription_prompt = ""
    if "optimization_prompt" not in st.session_state:
        st.session_state.optimization_prompt = ""
    
    # è¨­å®šé è¨­APIé‡‘é‘°
    if "openai_api_key" not in st.session_state:
        st.session_state["openai_api_key"] = ""
    if "elevenlabs_api_key" not in st.session_state:
        st.session_state["elevenlabs_api_key"] = ""
    if "gemini_api_key" not in st.session_state:
        st.session_state["gemini_api_key"] = ""
    if "use_llm" not in st.session_state:
        st.session_state["use_llm"] = False
    if "openai_model" not in st.session_state:
        st.session_state["openai_model"] = "o4-mini-transcribe"
    if "keyword_count" not in st.session_state:
        st.session_state["keyword_count"] = 10
    if "optimization_model" not in st.session_state:
        st.session_state["optimization_model"] = "o4-mini"

    # å‰µå»ºä¸»è¦çš„åŠŸèƒ½æ¨™ç±¤é ï¼Œæ·»åŠ æ­¥é©Ÿç·¨è™Ÿ
    tabs_titles = [
        "ğŸ“ Step 1: æ–‡ä»¶èˆ‡åœ–åƒè™•ç†", 
        "ğŸ™ï¸ Step 2: èªéŸ³è½‰æ–‡å­—", 
        "âœ¨ Step 3: æ–‡å­—å„ªåŒ–"
    ]
    main_tabs = st.tabs(tabs_titles)
    
    # æ–‡ä»¶è½‰æ›èˆ‡é—œéµè©æ¨™ç±¤é  (Step 1)
    with main_tabs[0]:
        render_markitdown_tab()
    
    # èªéŸ³è½‰æ–‡å­—æ¨™ç±¤é  (Step 2)
    with main_tabs[1]:
        with st.sidebar:
            st.header("è¨­å®š")
            
            # åˆ†æˆå…©å€‹æ¨™ç±¤é ï¼šè½‰éŒ„è¨­å®šå’Œå„ªåŒ–è¨­å®š
            tab1, tab2 = st.tabs(["ğŸ™ï¸ è½‰éŒ„è¨­å®š", "âœ¨ å„ªåŒ–è¨­å®š"])
            
            # è½‰éŒ„è¨­å®šæ¨™ç±¤é 
            with tab1:
                # é¸æ“‡è½‰éŒ„æœå‹™
                transcription_service = st.selectbox(
                    "é¸æ“‡è½‰éŒ„æœå‹™",
                    options=["OpenAI 2025 New", "Whisper", "ElevenLabs"],
                    index=0,
                    help="é¸æ“‡è¦ä½¿ç”¨çš„èªéŸ³è½‰æ–‡å­—æœå‹™"
                )
                
                # é¡¯ç¤ºæœå‹™èªªæ˜
                st.markdown(TRANSCRIPTION_SERVICE_INFO[transcription_service])
                
                # æ ¹æ“šé¸æ“‡çš„æœå‹™é¡¯ç¤ºå°æ‡‰çš„APIé‡‘é‘°è¼¸å…¥æ¡†
                if transcription_service == "OpenAI 2025 New":
                    # OpenAI API é‡‘é‘°
                    openai_api_key = st.text_input(
                        "OpenAI API é‡‘é‘°",
                        type="password",
                        value=st.session_state.get("openai_api_key", ""),
                        help="ç”¨æ–¼ OpenAI çš„èªéŸ³è½‰æ–‡å­—æœå‹™"
                    )
                    # å„²å­˜åˆ° session state
                    st.session_state["openai_api_key"] = openai_api_key
                    
                    # å…è¨±ç”¨æˆ¶é¸æ“‡è½‰éŒ„æ¨¡å‹
                    transcribe_model = st.radio(
                        "é¸æ“‡è½‰éŒ„æ¨¡å‹",
                        options=["gpt-4o-transcribe", "gpt-4o-mini-transcribe"],
                        index=1,  # é è¨­ä½¿ç”¨miniç‰ˆæœ¬
                        help=("gpt-4o-transcribeï¼šé«˜ç²¾åº¦ã€å¤šèªè¨€æ”¯æ´ï¼›"
                             "gpt-4o-mini-transcribeï¼šè¼•é‡å¿«é€Ÿã€æ€§åƒ¹æ¯”é«˜")
                    )
                    st.session_state["openai_model"] = transcribe_model
                    
                    # èªè¨€è¨­å®š
                    language_mode = st.radio(
                        "èªè¨€è¨­å®š",
                        options=["è‡ªå‹•åµæ¸¬", "æŒ‡å®šèªè¨€"],
                        help="é¸æ“‡éŸ³è¨Šçš„èªè¨€è™•ç†æ¨¡å¼"
                    )
                    
                    # èªè¨€è¨­å®š
                    if language_mode == "æŒ‡å®šèªè¨€":
                        languages = {
                            "ä¸­æ–‡ (ç¹é«”/ç°¡é«”)": "zh",
                            "è‹±æ–‡": "en",
                            "æ—¥æ–‡": "ja",
                            "éŸ“æ–‡": "ko",
                            "å…¶ä»–": "custom"
                        }
                        
                        selected_lang = st.selectbox(
                            "é¸æ“‡èªè¨€",
                            options=list(languages.keys())
                        )
                        
                        if selected_lang == "å…¶ä»–":
                            custom_lang = st.text_input(
                                "è¼¸å…¥èªè¨€ä»£ç¢¼",
                                placeholder="ä¾‹å¦‚ï¼šfr ä»£è¡¨æ³•æ–‡",
                                help="è«‹è¼¸å…¥ ISO 639-1 èªè¨€ä»£ç¢¼"
                            )
                            language_code = custom_lang if custom_lang else None
                        else:
                            language_code = languages[selected_lang]
                    else:
                        language_code = None
                
                elif transcription_service == "ElevenLabs":
                    # ElevenLabs API é‡‘é‘°
                    elevenlabs_api_key = st.text_input(
                        "ElevenLabs API é‡‘é‘°",
                        type="password",
                        help="ç”¨æ–¼ ElevenLabs èªéŸ³è½‰æ–‡å­—æœå‹™"
                    )
                    # å„²å­˜åˆ° session state
                    st.session_state["elevenlabs_api_key"] = elevenlabs_api_key
                
                # Whisper ç›¸é—œè¨­å®š
                elif transcription_service == "Whisper":
                    whisper_model = st.selectbox(
                        "é¸æ“‡ Whisper æ¨¡å‹",
                        options=["tiny", "base", "small", "medium", "large"],
                        index=2
                    )
                    st.session_state["whisper_model"] = whisper_model
                    st.caption(get_model_description(whisper_model))
                    
                    # èªè¨€è¨­å®š
                    language_mode = st.radio(
                        "èªè¨€è¨­å®š",
                        options=["è‡ªå‹•åµæ¸¬", "æŒ‡å®šèªè¨€", "æ··åˆèªè¨€"],
                        help="é¸æ“‡éŸ³è¨Šçš„èªè¨€è™•ç†æ¨¡å¼"
                    )
                    
                    if language_mode == "æŒ‡å®šèªè¨€":
                        languages = {
                            "ä¸­æ–‡ (ç¹é«”/ç°¡é«”)": "zh",
                            "è‹±æ–‡": "en",
                            "æ—¥æ–‡": "ja",
                            "éŸ“æ–‡": "ko",
                            "å…¶ä»–": "custom"
                        }
                        
                        selected_lang = st.selectbox(
                            "é¸æ“‡èªè¨€",
                            options=list(languages.keys())
                        )
                        
                        if selected_lang == "å…¶ä»–":
                            custom_lang = st.text_input(
                                "è¼¸å…¥èªè¨€ä»£ç¢¼",
                                placeholder="ä¾‹å¦‚ï¼šfr ä»£è¡¨æ³•æ–‡",
                                help="è«‹è¼¸å…¥ ISO 639-1 èªè¨€ä»£ç¢¼"
                            )
                            language_code = custom_lang if custom_lang else None
                        else:
                            language_code = languages[selected_lang]
                    else:
                        language_code = None
            
            # å„ªåŒ–è¨­å®šæ¨™ç±¤é 
            with tab2:
                # é¸æ“‡å„ªåŒ–æœå‹™
                optimization_service = st.selectbox(
                    "é¸æ“‡å„ªåŒ–æœå‹™",
                    ["Gemini", "OpenAI"],
                    help="é¸æ“‡è¦ä½¿ç”¨çš„æ–‡å­—å„ªåŒ–æœå‹™"
                )
                
                # é¡¯ç¤ºæœå‹™èªªæ˜
                st.markdown(OPTIMIZATION_SERVICE_INFO[optimization_service])
                
                # æ ¹æ“šé¸æ“‡çš„æœå‹™é¡¯ç¤ºå°æ‡‰çš„APIé‡‘é‘°è¼¸å…¥æ¡†
                if optimization_service == "Gemini":
                    # Gemini API é‡‘é‘°
                    gemini_api_key = st.text_input(
                        "Google API é‡‘é‘°",
                        type="password",
                        value=st.session_state.get("gemini_api_key", ""),
                        help="ç”¨æ–¼ Gemini æ¨¡å‹å„ªåŒ–æ–‡å­—"
                    )
                    # å„²å­˜åˆ° session state
                    st.session_state["gemini_api_key"] = gemini_api_key
                    
                    # æ·»åŠ æ¨¡å‹é¸æ“‡é¸é …
                    gemini_model = st.radio(
                        "é¸æ“‡ Gemini æ¨¡å‹",
                        options=[
                            "gemini-2.5-pro-preview-05-06", 
                            "gemini-2.5-flash-preview-04-17"
                        ],
                        index=0,
                        help="Pro ç‰ˆæœ¬åŠŸèƒ½æ›´å¼·å¤§ï¼ŒFlash ç‰ˆæœ¬é€Ÿåº¦æ›´å¿«"
                    )
                    st.session_state["gemini_model"] = gemini_model
                    
                    # é¡¯ç¤º Gemini æ¨¡å‹è³‡è¨Š
                    st.info(f"ä½¿ç”¨ {gemini_model} æ¨¡å‹é€²è¡Œå„ªåŒ–")
                else:  # OpenAI
                    # OpenAI API é‡‘é‘°
                    openai_api_key = st.text_input(
                        "OpenAI API é‡‘é‘°",
                        type="password",
                        value=st.session_state.get("openai_api_key", ""),
                        help="ç”¨æ–¼ OpenAI æ¨¡å‹å„ªåŒ–æ–‡å­—"
                    )
                    # å„²å­˜åˆ° session state
                    st.session_state["openai_api_key"] = openai_api_key
                    
                    # é¡¯ç¤ºæ¨¡å‹è³‡è¨Š
                    st.info("ä½¿ç”¨ o4-mini æ¨¡å‹é€²è¡Œå„ªåŒ–ï¼Œæ“æœ‰æ›´å¿«é€Ÿåº¦å’Œæ›´ä½æˆæœ¬")
                    st.session_state["optimization_model"] = "o4-mini"
                
                # å„ªåŒ–æç¤º (å¢åŠ æ–‡å­—å„ªåŒ–æ•ˆæœ)
                st.markdown("### å„ªåŒ–æç¤ºè¨­å®š")
                st.markdown("""
                æä¾›ä¸Šä¸‹æ–‡æˆ–ç‰¹å®šæŒ‡ç¤ºå¯ä»¥ä½¿æ¨¡å‹æ›´å¥½åœ°ç†è§£å…§å®¹ä¸¦ç”¢ç”Ÿæ›´ç¬¦åˆéœ€æ±‚çš„å„ªåŒ–çµæœã€‚
                """)
                
                optimization_prompt = st.text_area(
                    "å„ªåŒ–æç¤º (å¯é¸)",
                    value=st.session_state.get("optimization_prompt", ""),
                    placeholder="ä¾‹å¦‚ï¼šé€™æ˜¯ä¸€å ´é†«å­¸ç ”è¨æœƒçš„æ¼”è¬›ç¨¿ï¼Œè«‹ç‰¹åˆ¥æ³¨æ„é†«å­¸è¡“èªçš„æ­£ç¢ºæ€§ï¼Œä¸¦çµæ§‹åŒ–ç‚ºç°¡å ±æ ¼å¼...",
                    help="æä¾›ä¸Šä¸‹æ–‡æˆ–ç‰¹å®šæŒ‡ç¤ºï¼Œä»¥æå‡å„ªåŒ–æ•ˆæœ"
                )
                
                # å„²å­˜åˆ° session state
                st.session_state["optimization_prompt"] = optimization_prompt
                
                # å„ªåŒ–è¨­å®š
                temperature = st.slider(
                    "å‰µæ„ç¨‹åº¦",
                    0.0,
                    1.0,
                    0.5,
                    help="è¼ƒé«˜çš„å€¼æœƒç”¢ç”Ÿæ›´æœ‰å‰µæ„çš„çµæœï¼Œè¼ƒä½çš„å€¼æœƒç”¢ç”Ÿæ›´ä¿å®ˆçš„çµæœ"
                )
            
            # ä½œè€…è³‡è¨Š
            st.markdown("---")
            st.markdown("""
            ### Created by
            **Tseng Yao Hsien**  
            Endocrinologist  
            Tungs' Taichung MetroHarbor Hospital
            """)

        # èªéŸ³è½‰æ–‡å­—ä¸»è¦å…§å®¹
        st.header("Step 2: èªéŸ³è½‰æ–‡å­—")
        
        # ä¸Šå‚³æª”æ¡ˆ
        uploaded_file = st.file_uploader(
            "ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆ",
            type=["mp3", "wav", "ogg", "m4a"]
        )
        
        # åªé¡¯ç¤ºè½‰éŒ„æŒ‰éˆ•
        transcribe_button = st.button("ğŸ™ï¸ è½‰éŒ„éŸ³è¨Š", use_container_width=True)
        
        # é¡¯ç¤ºè½‰éŒ„çµæœï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        if st.session_state.transcribed_text:
            st.subheader("è½‰éŒ„çµæœ")
            
            # é¡¯ç¤ºè½‰éŒ„æ–‡å­—
            st.text_area(
                "è½‰éŒ„æ–‡å­—",
                st.session_state.transcribed_text,
                height=200
            )
            
            # ä¸‹è¼‰æŒ‰éˆ•
            st.markdown("### ä¸‹è¼‰é¸é …")
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰è½‰éŒ„æ–‡å­—",
                data=st.session_state.transcribed_text,
                file_name="transcription.txt",
                mime="text/plain",
                help="ä¸‹è¼‰è½‰éŒ„å¾Œçš„æ–‡å­—æª”æ¡ˆ",
                use_container_width=True,
                key="download_transcription"
            )
            
            # åªåœ¨æœ‰è½‰éŒ„æ–‡å­—æ™‚é¡¯ç¤ºå„ªåŒ–æŒ‰éˆ•ï¼Œæ·»åŠ  Step 3 æŒ‡ç¤º
            optimize_button = st.button("âœ¨ é€²å…¥ Step 3: å„ªåŒ–æ–‡å­—", use_container_width=True)
        else:
            optimize_button = False
        
        # è™•ç†è½‰éŒ„
        if uploaded_file and transcribe_button:
            # å¾session stateç²å–APIé‡‘é‘°
            openai_api_key = st.session_state.get("openai_api_key", "")
            elevenlabs_api_key = st.session_state.get("elevenlabs_api_key", "")
            
            if transcription_service == "OpenAI 2025 New" and not openai_api_key:
                st.error("è«‹æä¾› OpenAI API é‡‘é‘°")
                return
                
            if transcription_service == "ElevenLabs" and not elevenlabs_api_key:
                st.error("è«‹æä¾› ElevenLabs API é‡‘é‘°")
                return
            
            try:
                with st.spinner("è™•ç†ä¸­..."):
                    # åˆå§‹åŒ–è®Šæ•¸
                    full_transcript = ""
                    
                    # åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if transcription_service == "OpenAI 2025 New":
                        openai_client = OpenAI(api_key=openai_api_key)
                    
                    # è™•ç†ä¸Šå‚³çš„æª”æ¡ˆ
                    suffix = os.path.splitext(uploaded_file.name)[1]
                    with tempfile.NamedTemporaryFile(
                        delete=False,
                        suffix=suffix
                    ) as temp_file:
                        temp_file.write(uploaded_file.getvalue())
                        temp_path = temp_file.name
                    
                    try:
                        # æª¢æŸ¥éŸ³è¨Šé•·åº¦
                        try:
                            audio = AudioSegment.from_file(temp_path)
                            duration_seconds = len(audio) / 1000
                        except Exception as audio_error:
                            # å¦‚æœç„¡æ³•ä½¿ç”¨ AudioSegmentï¼ˆé€šå¸¸æ˜¯ç¼ºå°‘ ffmpegï¼‰ï¼Œç›´æ¥è™•ç†æ•´å€‹æª”æ¡ˆ
                            logger.warning(f"ç„¡æ³•åˆ†æéŸ³è¨Šé•·åº¦ï¼ˆå¯èƒ½ç¼ºå°‘ ffmpegï¼‰: {audio_error}")
                            st.warning("âš ï¸ åµæ¸¬åˆ°ç¼ºå°‘ ffmpegï¼Œå°‡ç›´æ¥è™•ç†æ•´å€‹éŸ³è¨Šæª”æ¡ˆï¼ˆå¯èƒ½è¼ƒæ…¢ï¼‰")
                            audio_segments = [temp_path]
                            duration_seconds = 0  # è¨­ç‚º 0 ä»¥è·³éåˆ†æ®µé‚è¼¯
                        
                        if duration_seconds > 600:  # å¦‚æœéŸ³è¨Šè¶…é 10 åˆ†é˜
                            st.info("éŸ³è¨Šè¼ƒé•·ï¼Œå°‡æ¡ç”¨å›ºå®šæ™‚é–“åˆ†æ®µè™•ç†...")
                            logger.info(
                                "éŸ³è¨Šæª”æ¡ˆé•·åº¦: %.2f ç§’ï¼Œé–‹å§‹å›ºå®šæ™‚é–“åˆ†æ®µè™•ç†",
                                duration_seconds
                            )
                            
                            # è¨­å®šåˆ†æ®µåƒæ•¸
                            MAX_SEGMENT_DURATION = 600  # æœ€å¤§åˆ†æ®µæ™‚é•·ï¼ˆç§’ï¼‰
                            OVERLAP_DURATION = 30      # é‡ç–Šæ™‚é•·ï¼ˆç§’ï¼‰
                            segments = []
                            start_time = 0.0
                            
                            # é€²è¡Œå›ºå®šæ™‚é–“åˆ†æ®µ
                            while start_time < duration_seconds:
                                end_time = min(
                                    start_time + MAX_SEGMENT_DURATION, 
                                    duration_seconds
                                )
                                
                                # å¦‚æœä¸æ˜¯ç¬¬ä¸€æ®µï¼Œå‰‡å¾å‰ä¸€æ®µçµå°¾æå‰é–‹å§‹
                                if start_time > 0:
                                    segment_start = start_time - OVERLAP_DURATION
                                else:
                                    segment_start = start_time
                                
                                # æ“·å–éŸ³è¨Šç‰‡æ®µ
                                segment = audio[
                                    int(segment_start * 1000):int(end_time * 1000)
                                ]
                                segment_path = f"{temp_path}_segment_{len(segments)}.mp3"
                                segment.export(segment_path, format="mp3")
                                logger.info(
                                    "å„²å­˜åˆ†æ®µ %dï¼Œæ™‚é–“ç¯„åœï¼š%.2f - %.2f ç§’",
                                    len(segments) + 1,
                                    segment_start,
                                    end_time
                                )
                                segments.append(segment_path)
                                
                                # æ›´æ–°é–‹å§‹æ™‚é–“
                                start_time = end_time
                            
                            audio_segments = segments
                            logger.info(
                                "å®Œæˆåˆ†æ®µè™•ç†ï¼Œå…± %d å€‹åˆ†æ®µ",
                                len(segments)
                            )
                        else:
                            audio_segments = [temp_path]
                            logger.info("éŸ³è¨Šé•·åº¦é©ä¸­ï¼Œä¸éœ€åˆ†æ®µè™•ç†")
                        
                        progress_bar = st.progress(0)
                        segment_results = []
                        
                        for i, segment_path in enumerate(audio_segments):
                            if transcription_service == "Whisper":
                                result = transcribe_audio_whisper(
                                    segment_path,
                                    model_name=whisper_model,
                                    language=language_code,
                                    initial_prompt=st.session_state["transcription_prompt"]
                                )
                            elif transcription_service == "ElevenLabs":
                                result = transcribe_audio_elevenlabs(
                                    api_key=elevenlabs_api_key,
                                    file_path=segment_path,
                                    language_code="zho",  # æŒ‡å®šä¸­æ–‡
                                    diarize=False  # å–æ¶ˆå•Ÿç”¨èªªè©±è€…è¾¨è­˜
                                )
                            elif transcription_service == "OpenAI 2025 New":
                                MAX_RETRIES = 3
                                retry_count = 0
                                failed = True
                                while retry_count < MAX_RETRIES:
                                    try:
                                        with open(segment_path, "rb") as audio_file:
                                            response = (
                                                openai_client.audio
                                                .transcriptions
                                                .create(
                                                    model=st.session_state["openai_model"],
                                                    file=audio_file,
                                                    language=language_code,
                                                    response_format="text",
                                                    prompt=st.session_state["transcription_prompt"],
                                                    temperature=0.3
                                                )
                                            )
                                            # æˆåŠŸå‰‡æ·»åŠ æ–‡å­—çµæœ
                                            segment_results.append(response)
                                            logger.info(
                                                "æˆåŠŸè½‰éŒ„åˆ†æ®µ %d/%d",
                                                i + 1,
                                                len(audio_segments)
                                            )
                                            failed = False
                                            break
                                    except Exception as e:
                                        retry_count += 1
                                        error_msg = str(e)
                                        if retry_count < MAX_RETRIES:
                                            logger.warning(
                                                "è™•ç†åˆ†æ®µ %d å¤±æ•— (é‡è©¦ %d/%d)ï¼š%s",
                                                i + 1,
                                                retry_count,
                                                MAX_RETRIES,
                                                error_msg
                                            )
                                            time.sleep(3)
                                        else:
                                            logger.error(
                                                "è™•ç†åˆ†æ®µ %d æœ€çµ‚å¤±æ•—ï¼š%s",
                                                i + 1,
                                                error_msg
                                            )
                                if failed:
                                    # è‹¥å…¨éƒ¨å˜—è©¦éƒ½å¤±æ•—ï¼Œé™„åŠ ç©ºå­—ä¸²ï¼Œç¢ºä¿å®Œæ•´æ’åº
                                    segment_results.append("")
                            
                            # æ›´æ–°é€²åº¦
                            progress = (i + 1) / len(audio_segments)
                            progress_bar.progress(progress)
                            
                            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                            try:
                                if segment_path != temp_path:
                                    os.remove(segment_path)
                                    logger.info(
                                        "å·²æ¸…ç†è‡¨æ™‚æª”æ¡ˆï¼š%s",
                                        segment_path
                                    )
                            except Exception as e:
                                logger.error(
                                    "æ¸…ç†è‡¨æ™‚æª”æ¡ˆå¤±æ•—ï¼š%s",
                                    str(e)
                                )
                        
                        # åˆä½µçµæœ
                        full_transcript = " ".join(segment_results)
                        logger.info("å®Œæˆæ‰€æœ‰åˆ†æ®µçš„è½‰éŒ„èˆ‡åˆä½µ")
                    
                    except Exception as e:
                        st.error(f"è™•ç†å¤±æ•—ï¼š{str(e)}")
                        logger.error(f"è™•ç†å¤±æ•—ï¼š{str(e)}")
                    
                    # è™•ç†è½‰éŒ„çµæœ
                    if full_transcript:
                        st.session_state.transcribed_text = full_transcript
                        st.rerun()  # ä½¿ç”¨æ–°çš„ rerun æ–¹æ³•
                    else:
                        st.error("è½‰éŒ„å¤±æ•—")
                        
            except Exception as e:
                st.error(f"è™•ç†å¤±æ•—ï¼š{str(e)}")
                logger.error(f"è™•ç†å¤±æ•—ï¼š{str(e)}")
        
        # å„ªåŒ–æ¨™ç±¤é  (Step 3)
        with main_tabs[2]:
            st.header("Step 3: æ–‡å­—å„ªåŒ–")
        
            # å¦‚æœæ²’æœ‰å¾…å„ªåŒ–çš„æ–‡å­—ï¼Œé¡¯ç¤ºæç¤º
            if not st.session_state.transcribed_text:
                st.info("è«‹å…ˆåœ¨ Step 1 è½‰æ›æ–‡ä»¶æˆ– Step 2 è½‰éŒ„éŸ³è¨Šï¼Œç„¶å¾Œå†åŸ·è¡Œå„ªåŒ–")
                return

            # é¡¯ç¤ºå„ªåŒ–çµæœï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
            if st.session_state.optimized_text:
                st.subheader("å„ªåŒ–çµæœ")
                
                # é¡¯ç¤ºå„ªåŒ–çµæœ
                st.text_area(
                    "å®Œæ•´å„ªåŒ–çµæœ",
                    st.session_state.full_result,
                    height=500
                )
                
                # ä¸‹è¼‰æŒ‰éˆ•å€åŸŸ
                st.markdown("### ä¸‹è¼‰é¸é …")
                col1, col2 = st.columns(2)
                
                with col1:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰ç´”æ–‡å­—æ ¼å¼",
                        data=st.session_state.full_result,  # å·²ç¶“æ˜¯ç´”æ–‡å­—æ ¼å¼ï¼Œä¸éœ€è¦é¡å¤–è™•ç†
                        file_name="optimized_result.txt",
                        mime="text/plain",
                        help="ä¸‹è¼‰ç´”æ–‡å­—æ ¼å¼çš„å®Œæ•´çµæœï¼ˆåŒ…å«å„ªåŒ–çµæœå’Œæ‘˜è¦ï¼‰",
                        use_container_width=True,
                        key="download_optimized_txt"
                    )
                
                with col2:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è¼‰ Markdown æ ¼å¼",
                        data=st.session_state.markdown_result,
                        file_name="optimized_result.md",
                        mime="text/markdown",
                        help="ä¸‹è¼‰ Markdown æ ¼å¼çš„å®Œæ•´çµæœï¼ˆåŒ…å«å„ªåŒ–çµæœå’Œæ‘˜è¦ï¼‰",
                        use_container_width=True,
                        key="download_optimized_md"
                    )
                
                # é¡¯ç¤ºè²»ç”¨çµ±è¨ˆï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
                if optimization_service == "OpenAI":
                    tokens_display = st.session_state.total_tokens
                    st.markdown(f"ç¸½ Tokens: **{tokens_display:,}**")
                    
                    # è¨ˆç®—è²»ç”¨
                    cost_result = calculate_cost(
                        st.session_state.input_tokens,
                        st.session_state.output_tokens,
                        st.session_state["optimization_model"],
                        is_cached=False
                    )
                    
                    st.markdown(f"ç¸½è²»ç”¨: **NT$ {cost_result[1]:.2f}**")
                    
                    # é¡¯ç¤ºè©³ç´°æˆæœ¬è³‡è¨Š
                    display_cost_info(
                        st.session_state.input_tokens,
                        st.session_state.output_tokens,
                        st.session_state["optimization_model"],
                        is_cached=False
                    )
                else:
                    st.info("Gemini API ä½¿ç”¨é‡æš«ä¸è¨ˆè²»")
            else:
                # å¦‚æœæœ‰æ–‡å­—ä½†å°šæœªå„ªåŒ–ï¼Œé¡¯ç¤ºå„ªåŒ–æŒ‰éˆ•
                st.text_area(
                    "å¾…å„ªåŒ–æ–‡å­—",
                    st.session_state.transcribed_text,
                    height=300
                )
                
                optimize_button = st.button("âœ¨ å„ªåŒ–æ–‡å­—", use_container_width=True)
                
                # è™•ç†å„ªåŒ–
                if optimize_button:
                    try:
                        with st.spinner("å„ªåŒ–ä¸­..."):
                            # å¾ session state ç²å– API é‡‘é‘°
                            openai_api_key = st.session_state.get("openai_api_key", "")
                            gemini_api_key = st.session_state.get("gemini_api_key", "")
                            
                            if optimization_service == "OpenAI":
                                if not openai_api_key:
                                    st.error("è«‹åœ¨å´é‚Šæ¬„æä¾› OpenAI API é‡‘é‘°")
                                    return
                                    
                                refined = refine_transcript(
                                    raw_text=st.session_state.transcribed_text,
                                    api_key=openai_api_key,
                                    model=st.session_state["optimization_model"],
                                    temperature=temperature,
                                    context=st.session_state["optimization_prompt"]
                                )
                            else:  # Gemini
                                if not gemini_api_key:
                                    st.error("è«‹åœ¨å´é‚Šæ¬„æä¾› Google API é‡‘é‘°")
                                    return
                                    
                                refined = refine_transcript_gemini(
                                    text=st.session_state.transcribed_text,
                                    api_key=gemini_api_key,
                                    temperature=temperature,
                                    context=st.session_state["optimization_prompt"]
                                )
                            
                            if refined:
                                # å„²å­˜å„ªåŒ–çµæœåˆ° session state
                                st.session_state.optimized_text = refined["corrected"]
                                st.session_state.summary_text = refined["summary"]
                                
                                # ç§»é™¤ Markdown æ¨™è¨˜çš„å‡½æ•¸
                                def remove_markdown(text):
                                    # ç§»é™¤æ¨™é¡Œç¬¦è™Ÿ (#)
                                    text = text.replace('#', '')
                                    # ç§»é™¤ç²—é«”æ¨™è¨˜ (**)
                                    text = text.replace('**', '')
                                    # ç§»é™¤æ–œé«”æ¨™è¨˜ (*)
                                    text = text.replace('*', '')
                                    # ç§»é™¤åˆ†éš”ç·š (---)
                                    text = text.replace('---', '')
                                    # ç§»é™¤å¤šé¤˜çš„ç©ºè¡Œ
                                    text = "\n".join(
                                        line.strip() 
                                        for line in text.split("\n") 
                                        if line.strip()
                                    )
                                    return text
                                
                                # çµ„åˆå®Œæ•´çµæœæ–‡å­—ï¼ˆç´”æ–‡å­—æ ¼å¼ï¼Œç§»é™¤æ‰€æœ‰ Markdown æ¨™è¨˜ï¼‰
                                st.session_state.full_result = f"""å„ªåŒ–å¾Œæ–‡å­—ï¼š
{remove_markdown(refined["corrected"])}

é‡é»æ‘˜è¦ï¼š
{remove_markdown(refined["summary"])}"""

                                # Markdown æ ¼å¼çš„çµæœï¼ˆä¿ç•™ Markdown æ¨™è¨˜ï¼‰
                                st.session_state.markdown_result = f"""# å„ªåŒ–çµæœ

## å„ªåŒ–å¾Œæ–‡å­—
{refined["corrected"]}

## é‡é»æ‘˜è¦
{refined["summary"]}"""
                                
                                # æ›´æ–° token ä½¿ç”¨çµ±è¨ˆ
                                current_usage = refined.get("usage", {})
                                st.session_state.input_tokens = current_usage.get(
                                    "total_input_tokens",
                                    0
                                )
                                st.session_state.output_tokens = current_usage.get(
                                    "total_output_tokens",
                                    0
                                )
                                st.session_state.total_tokens = (
                                    st.session_state.input_tokens +
                                    st.session_state.output_tokens
                                )
                                
                                st.rerun()
                            else:
                                st.error("æ–‡å­—å„ªåŒ–å¤±æ•—")
                    except Exception as e:
                        st.error(f"å„ªåŒ–å¤±æ•—ï¼š{str(e)}")
                        logger.error(f"å„ªåŒ–å¤±æ•—ï¼š{str(e)}")

    # ç§»é™¤é—œæ–¼æ¨™ç±¤é çš„å…§å®¹ï¼Œæ”¹ç‚ºåœ¨å´é‚Šæ¬„é¡¯ç¤º
    with st.sidebar:
        # åˆ†éš”ç·š
        st.markdown("---")
        
        # é—œæ–¼è³‡è¨Š
        with st.expander("â„¹ï¸ é—œæ–¼", expanded=False):
            st.markdown("""
            ### éŸ³è¨Šè½‰æ–‡å­—èˆ‡æ–‡ä»¶è™•ç†ç³»çµ±
            
            æœ¬ç³»çµ±æä¾›ä»¥ä¸‹åŠŸèƒ½ï¼š
            
            1. **æ–‡ä»¶è½‰æ›èˆ‡é—œéµè©**ï¼šå°‡å„ç¨®æ ¼å¼æ–‡ä»¶è½‰ç‚º Markdown
            2. **èªéŸ³è½‰æ–‡å­—**ï¼šå°‡éŸ³è¨Šæª”æ¡ˆè½‰æ›ç‚ºæ–‡å­—
            3. **æ–‡å­—å„ªåŒ–**ï¼šå„ªåŒ–è½‰éŒ„æ–‡å­—ï¼Œè£½ä½œæœƒè­°è¨˜éŒ„æˆ–è¬›ç¨¿
            
            ### æŠ€è¡“æ”¯æ´
            * éŸ³è¨Šè½‰æ–‡å­—ï¼šOpenAI æ¨¡å‹ã€Whisper æ¨¡å‹
            * æ–‡å­—å„ªåŒ–ï¼šGPT-4o ç³»åˆ—æ¨¡å‹ã€Gemini 2.5 Pro
            * æ–‡ä»¶è½‰æ›ï¼šMarkItDown å¥—ä»¶
            
            ### ç‰ˆæœ¬è³‡è¨Š
            * ç‰ˆæœ¬ï¼š1.1.0
            * æ›´æ–°æ—¥æœŸï¼š2025-04-20
            * æ–°å¢åŠŸèƒ½ï¼šæ–‡ä»¶è½‰æ›èˆ‡é—œéµè©æå–
            """)


if __name__ == "__main__":
    main() 