@mcp.tool()
def search_knowledge_base(query: str) -> str:
    """ä½¿ç”¨LlamaIndexæœç´¢çŸ¥è­˜åº«ï¼Œç²å–ç›¸é—œä¿¡æ¯ã€‚
    
    Args:
        query: æœç´¢æŸ¥è©¢
    
    Returns:
        æœç´¢çµæœçš„æ–‡æœ¬
    """
    try:
        llama_cloud_api_key = os.environ.get("LLAMA_CLOUD_API_KEY")
        
        if not llama_cloud_api_key:
            return json.dumps({"error": "è«‹æä¾›Llama Cloud APIå¯†é‘°"})
            
        index = LlamaCloudIndex(
            name="image-analysis-knowledge-base",
            project_name="åœ–åƒåˆ†æå°ˆæ¡ˆ",
            api_key=llama_cloud_api_key,
        )
        
        response = index.as_query_engine().query(query)
        return str(response)
    except Exception as e:
        error_msg = f"æœç´¢çŸ¥è­˜åº«éŒ¯èª¤: {e}"
        logger.error(error_msg)
        return json.dumps({"error": error_msg})

@mcp.tool()
def extract_text_from_image(image_base64: str) -> str:
    """å¾åœ–åƒä¸­æå–ç´”æ–‡å­—å…§å®¹ã€‚
    
    Args:
        image_base64: åœ–åƒçš„base64ç·¨ç¢¼å­—ç¬¦ä¸²
    
    Returns:
        æå–çš„æ–‡å­—å…§å®¹
    """
    openai_api_key = os.environ.get("OPENAI_API_KEY", "")
    
    if not openai_api_key:
        return json.dumps({"error": "è«‹æä¾›OpenAI APIå¯†é‘°"})
        
    try:
        client = OpenAI(api_key=openai_api_key)
        
        # å°ˆæ³¨æ–¼OCRçš„æç¤ºè©
        prompt = """è«‹æå–æ­¤åœ–åƒä¸­çš„æ‰€æœ‰æ–‡å­—ã€‚åªè¿”å›åœ–åƒä¸­çš„æ–‡å­—å…§å®¹ï¼Œä¿æŒåŸå§‹æ ¼å¼å’Œæ®µè½çµæ§‹ã€‚ä¸è¦æ·»åŠ ä»»ä½•è§£é‡‹æˆ–æè¿°ã€‚"""
        
        # èª¿ç”¨OpenAI API
        response = client.chat.completions.create(
            model="gpt-4-vision-preview",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            }
                        }
                    ]
                }
            ],
            max_completion_tokens=1000
        )
        
        return response.choices[0].message.content
            
    except Exception as e:
        error_type = "æ–‡å­—æå–éŒ¯èª¤"
        error_msg = f"{error_type}: {e}"
        logger.error(error_msg)
        return json.dumps({"error": error_msg})

@mcp.tool()
def image_to_structured_data(image_base64: str, schema: str) -> str:
    """å¾åœ–åƒæå–çµæ§‹åŒ–æ•¸æ“šï¼ŒåŸºæ–¼æä¾›çš„schemaã€‚
    
    Args:
        image_base64: åœ–åƒçš„base64ç·¨ç¢¼å­—ç¬¦ä¸²
        schema: æè¿°è¦æå–çš„çµæ§‹åŒ–æ•¸æ“šæ ¼å¼çš„JSON schema
    
    Returns:
        ç¬¦åˆschemaçš„çµæ§‹åŒ–JSONæ•¸æ“š
    """
    openai_api_key = os.environ.get("OPENAI_API_KEY", "")
    
    if not openai_api_key:
        return json.dumps({"error": "è«‹æä¾›OpenAI APIå¯†é‘°"})
        
    try:
        client = OpenAI(api_key=openai_api_key)
        
        # å°ˆæ³¨æ–¼çµæ§‹åŒ–æ•¸æ“šæå–çš„æç¤ºè©
        prompt = f"""åˆ†æé€™å¼µåœ–åƒä¸¦æå–ç¬¦åˆä»¥ä¸‹JSON schemaçš„çµæ§‹åŒ–æ•¸æ“š:
        
        {schema}
        
        è«‹ç¢ºä¿è¿”å›çš„å…§å®¹æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œä¸¦ä¸”ç¬¦åˆä¸Šè¿°schemaã€‚"""
        
        # èª¿ç”¨OpenAI API
        response = client.chat.completions.create(
            model="gpt-4-vision-preview",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_base64}"
                            }
                        }
                    ]
                }
            ],
            max_completion_tokens=1500
        )
        
        return response.choices[0].message.content
            
    except Exception as e:
        error_type = "çµæ§‹åŒ–æ•¸æ“šæå–éŒ¯èª¤"
        error_msg = f"{error_type}: {e}"
        logger.error(error_msg)
        return json.dumps({"error": error_msg})

@mcp.tool()
def analyze_document_image_with_llamaparse(image_base64: str) -> str:
    """ä½¿ç”¨LlamaParseåˆ†ææ–‡æª”åœ–åƒï¼Œæå–çµæ§‹åŒ–ä¿¡æ¯ã€‚
    
    Args:
        image_base64: æ–‡æª”åœ–åƒçš„base64ç·¨ç¢¼å­—ç¬¦ä¸²
    
    Returns:
        åˆ†æçµæœçš„æ–‡æœ¬
    """
    try:
        # é¦–å…ˆå°‡base64åœ–åƒä¿å­˜ç‚ºè‡¨æ™‚æ–‡ä»¶
        import tempfile
        import base64
        
        llama_cloud_api_key = os.environ.get("LLAMA_CLOUD_API_KEY")
        if not llama_cloud_api_key:
            return json.dumps({"error": "è«‹æä¾›Llama Cloud APIå¯†é‘°"})
        
        # å‰µå»ºè‡¨æ™‚æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as temp_file:
            temp_file_path = temp_file.name
            temp_file.write(base64.b64decode(image_base64))
        
        # ä½¿ç”¨LlamaParseåˆ†æ
        parser = LlamaParse(
            api_key=llama_cloud_api_key
        )
        
        documents = parser.load_data(temp_file_path)
        
        # åˆªé™¤è‡¨æ™‚æ–‡ä»¶
        os.unlink(temp_file_path)
        
        # è¿”å›çµæ§‹åŒ–åˆ†æçµæœ
        results = []
        for doc in documents:
            results.append({
                "content": doc.text,
                "metadata": doc.metadata
            })
            
        return json.dumps(results, ensure_ascii=False)
    except Exception as e:
        error_msg = f"LlamaParseåˆ†ææ–‡æª”åœ–åƒéŒ¯èª¤: {e}"
        logger.error(error_msg)
        return json.dumps({"error": error_msg})

# ä¸»è¦Streamlitæ‡‰ç”¨ç•Œé¢
def main():
    """ä¸»æ‡‰ç”¨ç¨‹å¼å…¥å£é»"""
    st.set_page_config(
        page_title="é€²éšåœ–åƒåˆ†æå·¥å…·",
        page_icon="ğŸ”",
        layout="wide"
    )
    
    st.title("ğŸ” é€²éšåœ–åƒåˆ†æèˆ‡çŸ¥è­˜æå–å·¥å…·")
    st.write("ä¸Šå‚³åœ–åƒæˆ–æ–‡æª”é€²è¡Œåˆ†æã€é—œéµè©æå–å’ŒçŸ¥è­˜åº«æœç´¢")
    
    # å´é‚Šæ¬„è¨­ç½®
    with st.sidebar:
        st.header("APIè¨­ç½®")
        
        # APIå¯†é‘°è¼¸å…¥
        openai_api_key = st.text_input(
            "OpenAI APIå¯†é‘°",
            type="password",
            value=os.environ.get("OPENAI_API_KEY", ""),
            help="è¼¸å…¥æ‚¨çš„OpenAI APIå¯†é‘°ä»¥ä½¿ç”¨Visionæ¨¡å‹"
        )
        
        llama_cloud_api_key = st.text_input(
            "Llama Cloud APIå¯†é‘°",
            type="password",
            value=os.environ.get("LLAMA_CLOUD_API_KEY", ""),
            help="è¼¸å…¥æ‚¨çš„Llama Cloud APIå¯†é‘°ä»¥ä½¿ç”¨LlamaParseå’ŒLlamaIndex"
        )
        
        # ä¿å­˜APIå¯†é‘°åˆ°ç’°å¢ƒè®Šæ•¸
        if openai_api_key:
            os.environ["OPENAI_API_KEY"] = openai_api_key
            
        if llama_cloud_api_key:
            os.environ["LLAMA_CLOUD_API_KEY"] = llama_cloud_api_key
        
        st.header("åˆ†æé¸é …")
        analysis_mode = st.radio(
            "é¸æ“‡åˆ†ææ¨¡å¼",
            options=["åŸºæœ¬åˆ†æ", "æ–‡å­—æå–", "çµæ§‹åŒ–æ•¸æ“š", "æ–‡æª”åˆ†æ", "çŸ¥è­˜åº«æœç´¢"],
            help="é¸æ“‡é©åˆæ‚¨éœ€æ±‚çš„åˆ†ææ¨¡å¼"
        )
        
        # è‡ªå®šç¾©æç¤ºè©
        if analysis_mode in ["åŸºæœ¬åˆ†æ", "çµæ§‹åŒ–æ•¸æ“š"]:
            custom_prompt = st.text_area(
                "è‡ªå®šç¾©æç¤ºè© (é¸å¡«)",
                placeholder="è¼¸å…¥è‡ªå®šç¾©æç¤ºè©ä¾†å‘Šè¨´AIå¦‚ä½•åˆ†æåœ–åƒ...",
                help="ç•™ç©ºå°‡ä½¿ç”¨é»˜èªæç¤ºè©"
            )
        
        # çµæ§‹åŒ–æ•¸æ“šæ¨¡å¼çš„schemaè¼¸å…¥
        if analysis_mode == "çµæ§‹åŒ–æ•¸æ“š":
            default_schema = """{
  "type": "object",
  "properties": {
    "title": {"type": "string"},
    "keywords": {"type": "array", "items": {"type": "string"}},
    "main_objects": {"type": "array", "items": {"type": "string"}},
    "text_content": {"type": "string"}
  }
}"""
            schema_input = st.text_area(
                "JSON Schema",
                value=default_schema,
                help="å®šç¾©è¦å¾åœ–åƒæå–çš„çµæ§‹åŒ–æ•¸æ“šæ ¼å¼"
            )
        
        # çŸ¥è­˜åº«æœç´¢çš„æŸ¥è©¢è¼¸å…¥
        if analysis_mode == "çŸ¥è­˜åº«æœç´¢":
            query_input = st.text_input(
                "æœç´¢æŸ¥è©¢",
                placeholder="è¼¸å…¥æ‚¨æƒ³æœç´¢çš„å…§å®¹...",
                help="åŸºæ–¼æ‚¨çš„åœ–åƒå…§å®¹è‡ªå‹•ç”Ÿæˆæœç´¢æŸ¥è©¢"
            )
    
    # ä¸»å€åŸŸè¨­ç½®
    upload_col, result_col = st.columns([1, 1])
    
    with upload_col:
        st.subheader("ä¸Šå‚³å…§å®¹")
        
        if analysis_mode == "æ–‡æª”åˆ†æ":
            uploaded_files = st.file_uploader(
                "é¸æ“‡æ–‡æª”æˆ–åœ–åƒ",
                type=SUPPORTED_FORMATS + ["pdf", "docx", "txt"],
                accept_multiple_files=True,
                help="æ”¯æ´å¤šç¨®æ–‡æª”å’Œåœ–åƒæ ¼å¼"
            )
        else:
            uploaded_files = st.file_uploader(
                "é¸æ“‡ä¸€å¼µæˆ–å¤šå¼µåœ–åƒ",
                type=SUPPORTED_FORMATS,
                accept_multiple_files=True,
                help=f"æ”¯æ´çš„æ ¼å¼: {', '.join(SUPPORTED_FORMATS)}"
            )
        
        analyze_button_disabled = not uploaded_files or (
            not openai_api_key and analysis_mode in ["åŸºæœ¬åˆ†æ", "æ–‡å­—æå–", "çµæ§‹åŒ–æ•¸æ“š"]) or (
            not llama_cloud_api_key and analysis_mode in ["æ–‡æª”åˆ†æ", "çŸ¥è­˜åº«æœç´¢"])
        
        if st.button("é–‹å§‹åˆ†æ", disabled=analyze_button_disabled):
            with st.spinner("åˆ†æä¸­..."):
                results = {}
                
                for i, uploaded_file in enumerate(uploaded_files):
                    file_name = uploaded_file.name
                    st.write(f"æ­£åœ¨è™•ç† {file_name}...")
                    
                    # è®€å–ä¸Šå‚³çš„æ–‡ä»¶
                    file_data = uploaded_file.read()
                    
                    # è™•ç†HEICæ ¼å¼åœ–åƒ
                    if file_name.lower().endswith((".heic", ".heif")):
                        try:
                            image = Image.open(io.BytesIO(file_data))
                            buffer = io.BytesIO()
                            image.save(buffer, format="JPEG")
                            file_data = buffer.getvalue()
                        except Exception as e:
                            results[file_name] = {"error": f"è½‰æ›HEICåœ–åƒéŒ¯èª¤: {e}"}
                            continue
                    
                    # å°‡æ–‡ä»¶æ•¸æ“šè½‰æ›ç‚ºbase64
                    import base64
                    file_base64 = base64.b64encode(file_data).decode('utf-8')
                    
                    # æ ¹æ“šåˆ†ææ¨¡å¼èª¿ç”¨ä¸åŒçš„å·¥å…·
                    try:
                        if analysis_mode == "åŸºæœ¬åˆ†æ":
                            tool_result = extract_image_keywords(
                                file_base64, 
                                custom_prompt if 'custom_prompt' in locals() else None
                            )
                            # å˜—è©¦è§£æJSON
                            try:
                                results[file_name] = json.loads(tool_result)
                            except:
                                results[file_name] = {"result": tool_result}
                                
                        elif analysis_mode == "æ–‡å­—æå–":
                            tool_result = extract_text_from_image(file_base64)
                            results[file_name] = {"text": tool_result}
                            
                        elif analysis_mode == "çµæ§‹åŒ–æ•¸æ“š":
                            tool_result = image_to_structured_data(
                                file_base64, 
                                schema_input if 'schema_input' in locals() else default_schema
                            )
                            # å˜—è©¦è§£æJSON
                            try:
                                results[file_name] = json.loads(tool_result)
                            except:
                                results[file_name] = {"result": tool_result}
                                
                        elif analysis_mode == "æ–‡æª”åˆ†æ":
                            # å¦‚æœæ˜¯PDFç­‰æ–‡æª”æ ¼å¼ï¼Œä¿å­˜ç‚ºè‡¨æ™‚æ–‡ä»¶
                            if file_name.lower().endswith((".pdf", ".docx", ".txt")):
                                with tempfile.NamedTemporaryFile(suffix=f".{file_name.split('.')[-1]}", delete=False) as temp_file:
                                    temp_file_path = temp_file.name
                                    temp_file.write(file_data)
                                tool_result = analyze_document_with_llama_parse(temp_file_path)
                                os.unlink(temp_file_path)  # åˆªé™¤è‡¨æ™‚æ–‡ä»¶
                            else:
                                # è™•ç†åœ–åƒæ–‡æª”
                                tool_result = analyze_document_image_with_llamaparse(file_base64)
                            
                            # å˜—è©¦è§£æJSON
                            try:
                                results[file_name] = json.loads(tool_result)
                            except:
                                results[file_name] = {"result": tool_result}
                                
                        elif analysis_mode == "çŸ¥è­˜åº«æœç´¢":
                            # é¦–å…ˆæå–åœ–åƒæ–‡å­—ï¼Œç„¶å¾ŒåŸºæ–¼æ–‡å­—å…§å®¹æœç´¢
                            extracted_text = extract_text_from_image(file_base64)
                            
                            # ç”Ÿæˆæœç´¢æŸ¥è©¢
                            search_query = query_input if query_input else f"é—œæ–¼ä»¥ä¸‹å…§å®¹çš„é‡è¦ä¿¡æ¯: {extracted_text[:200]}"
                            
                            # åŸ·è¡Œæœç´¢
                            tool_result = search_knowledge_base(search_query)
                            results[file_name] = {
                                "extracted_text": extracted_text,
                                "search_query": search_query,
                                "search_result": tool_result
                            }
                    
                    except Exception as e:
                        error_type = "è™•ç†éŒ¯èª¤"
                        error_msg = f"{error_type}: {e}"
                        logger.error(error_msg)
                        results[file_name] = {"error": error_msg}
                
                # é¡¯ç¤ºçµæœ
                st.session_state.results = results
    
    # é¡¯ç¤ºçµæœ
    with result_col:
        st.subheader("åˆ†æçµæœ")
        
        if "results" in st.session_state and st.session_state.results:
            # å‰µå»ºä¸‹è¼‰æŒ‰éˆ•
            json_results = json.dumps(st.session_state.results, ensure_ascii=False, indent=2)
            st.download_button(
                label="ä¸‹è¼‰å®Œæ•´çµæœ (JSON)",
                data=json_results,
                file_name="analysis_results.json",
                mime="application/json"
            )
            
            # é¡¯ç¤ºæ¯å€‹æ–‡ä»¶çš„çµæœ
            for file_name, result in st.session_state.results.items():
                with st.expander(f"æ–‡ä»¶: {file_name}", expanded=True):
                    if "error" in result:
                        st.error(f"éŒ¯èª¤: {result['error']}")
                        continue
                    
                    # åŸºæ–¼åˆ†ææ¨¡å¼é¡¯ç¤ºä¸åŒçš„çµæœ
                    if analysis_mode == "åŸºæœ¬åˆ†æ":
                        # é¡¯ç¤ºé—œéµè©
                        if "keywords" in result:
                            st.write("**é—œéµè©:**")
                            if isinstance(result["keywords"], list):
                                st.write(", ".join(result["keywords"]))
                            else:
                                st.write(result["keywords"])
                        
                        # é¡¯ç¤ºæè¿°
                        if "description" in result:
                            st.write("**æè¿°:**")
                            st.write(result["description"])
                        
                        # é¡¯ç¤ºå…¶ä»–ä¿¡æ¯
                        cols = st.columns(2)
                        
                        with cols[0]:
                            if "main_colors" in result:
                                st.write("**ä¸»è¦é¡è‰²:**")
                                if isinstance(result["main_colors"], list):
                                    for color in result["main_colors"]:
                                        st.write(f"- {color}")
                                else:
                                    st.write(result["main_colors"])
                        
                        with cols[1]:
                            if "objects" in result:
                                st.write("**è­˜åˆ¥çš„ç‰©é«”:**")
                                if isinstance(result["objects"], list):
                                    for obj in result["objects"]:
                                        st.write(f"- {obj}")
                                else:
                                    st.write(result["objects"])
                        
                        # é¡¯ç¤ºè­˜åˆ¥çš„æ–‡å­—
                        if "text" in result:
                            st.write("**è­˜åˆ¥çš„æ–‡å­—:**")
                            st.write(result["text"])
                    
                    elif analysis_mode == "æ–‡å­—æå–":
                        st.write("**æå–çš„æ–‡å­—:**")
                        st.write(result.get("text", "ç„¡æ³•æå–æ–‡å­—"))
                    
                    elif analysis_mode == "çµæ§‹åŒ–æ•¸æ“š":
                        # é¡¯ç¤ºçµæ§‹åŒ–æ•¸æ“š
                        for key, value in result.items():
                            if key != "result" and key != "raw":
                                st.write(f"**{key}:**")
                                if isinstance(value, list):
                                    for item in value:
                                        st.write(f"- {item}")
                                else:
                                    st.write(value)
                    
                    elif analysis_mode == "æ–‡æª”åˆ†æ":
                        # é¡¯ç¤ºæ–‡æª”åˆ†æçµæœ
                        if isinstance(result, list):
                            for doc_result in result:
                                st.write("**æ–‡æª”å…§å®¹:**")
                                st.write(doc_result.get("content", "ç„¡å…§å®¹"))
                                
                                st.write("**å…ƒæ•¸æ“š:**")
                                for meta_key, meta_value in doc_result.get("metadata", {}).items():
                                    st.write(f"- {meta_key}: {meta_value}")
                        else:
                            st.write(result.get("result", json.dumps(result, ensure_ascii=False)))
                    
                    elif analysis_mode == "çŸ¥è­˜åº«æœç´¢":
                        st.write("**æå–çš„æ–‡å­—:**")
                        st.write(result.get("extracted_text", "ç„¡æ³•æå–æ–‡å­—"))
                        
                        st.write("**æœç´¢æŸ¥è©¢:**")
                        st.write(result.get("search_query", "ç„¡æœç´¢æŸ¥è©¢"))
                        
                        st.write("**æœç´¢çµæœ:**")
                        st.write(result.get("search_result", "ç„¡æœç´¢çµæœ"))
                    
                    # é¡¯ç¤ºåŸå§‹çµæœ
                    with st.expander("æŸ¥çœ‹åŸå§‹æ•¸æ“š"):
                        st.code(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            st.info("ä¸Šå‚³å…§å®¹ä¸¦é»æ“Šåˆ†ææŒ‰éˆ•ä»¥æŸ¥çœ‹çµæœ")

    # é¡¯ç¤ºMCPæœå‹™å™¨ä¿¡æ¯
    with st.expander("MCPæœå‹™å™¨ä¿¡æ¯"):
        st.markdown("""
        ### MCPæœå‹™å™¨å·²å•Ÿå‹•
        
        æœ¬æ‡‰ç”¨æ•´åˆäº†ä»¥ä¸‹LlamaMCPå·¥å…·:
        
        1. **extract_image_keywords** - ä½¿ç”¨Vision APIæå–åœ–åƒé—œéµè©
        2. **extract_text_from_image** - å¾åœ–åƒæå–ç´”æ–‡å­—
        3. **image_to_structured_data** - æå–ç¬¦åˆSchemaçš„çµæ§‹åŒ–æ•¸æ“š
        4. **analyze_document_with_llama_parse** - ä½¿ç”¨LlamaParseåˆ†ææ–‡æª”
        5. **analyze_document_image_with_llamaparse** - åˆ†ææ–‡æª”åœ–åƒ
        6. **search_knowledge_base** - æœç´¢LlamaIndexçŸ¥è­˜åº«
        
        å¦‚éœ€å°‡é€™äº›å·¥å…·é€£æ¥åˆ°Claude Desktopæˆ–å…¶ä»–æ”¯æŒMCPçš„å®¢æˆ¶ç«¯ï¼Œè«‹ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š
        ```
        python mcp-server.py
        ```
        
        è©³ç´°é…ç½®èªªæ˜è«‹åƒè€ƒ: [LlamaCloud MCP GitHub](https://github.com/run-llama/llamacloud-mcp)
        """)

# å•Ÿå‹•MCPæœå‹™å™¨å’ŒStreamlitæ‡‰ç”¨
if __name__ == "__main__":
    import threading
    import asyncio
    
    # å•Ÿå‹•MCPæœå‹™å™¨
    def run_mcp_server():
        asyncio.run(mcp.run_sse_async())
    
    # åœ¨å–®ç¨çš„ç·šç¨‹ä¸­å•Ÿå‹•MCPæœå‹™å™¨
    server_thread = threading.Thread(target=run_mcp_server)
    server_thread.daemon = True
    server_thread.start()
    
    # å•Ÿå‹•Streamlitæ‡‰ç”¨
    main()